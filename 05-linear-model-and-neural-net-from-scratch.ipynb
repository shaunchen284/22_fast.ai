{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Introduction"]},{"cell_type":"markdown","metadata":{},"source":["In this notebook we're going to build and train a deep learning model \"from scratch\" -- by which I mean that we're not going to use any pre-built architecture, or optimizers, or data loading frameworks, etc.\n","\n","We'll be assuming you already know the basics of how a neural network works. If you don't, read this notebook first: [How does a neural net really work?\n","](https://www.kaggle.com/code/jhoward/how-does-a-neural-net-really-work). We'll be using Kaggle's [Titanic](https://www.kaggle.com/competitions/titanic/) competition in this notebook, because it's very small and simple, but also has displays many of the tricky real-life issues that we need to handle in most practical projects. (Note, however, that this competition is a small \"learner\" competition on Kaggle, so don't expect to actually see much benefits from using a neural net just yet; that will come once we try our some real competitions!)\n","\n","It's great to be able to run the same notebook on your own machine or Colab, as well as Kaggle. To allow for this, we use this code to download the data as needed when not on Kaggle (see [this notebook](https://www.kaggle.com/code/jhoward/getting-started-with-nlp-for-absolute-beginners/) for details about this technique):"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:34:17.763822Z","iopub.status.busy":"2022-05-30T22:34:17.763494Z","iopub.status.idle":"2022-05-30T22:34:17.771348Z","shell.execute_reply":"2022-05-30T22:34:17.770444Z","shell.execute_reply.started":"2022-05-30T22:34:17.763787Z"},"trusted":true},"outputs":[],"source":["import os\n","from pathlib import Path\n","\n","iskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\n","if iskaggle: path = Path('../input/titanic')\n","else:\n","    path = Path('titanic')\n","    if not path.exists():\n","        import zipfile,kaggle\n","        kaggle.api.competition_download_cli(str(path))\n","        zipfile.ZipFile(f'{path}.zip').extractall(path)"]},{"cell_type":"markdown","metadata":{"hidden":true},"source":["Note that the data for Kaggle comps always lives in the `../input` folder. The easiest way to get the path is to click the \"K\" button in the top-right of the Kaggle notebook, click on the folder shown there, and click the copy button.\n","\n","We'll be using *numpy* and *pytorch* for array calculations in this notebook, and *pandas* for working with tabular data, so we'll import them and set them to display using a bit more space than they default to."]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:34:17.811857Z","iopub.status.busy":"2022-05-30T22:34:17.810967Z","iopub.status.idle":"2022-05-30T22:34:17.817725Z","shell.execute_reply":"2022-05-30T22:34:17.816849Z","shell.execute_reply.started":"2022-05-30T22:34:17.811797Z"},"trusted":true},"outputs":[],"source":["import torch, numpy as np, pandas as pd\n","np.set_printoptions(linewidth=140)\n","torch.set_printoptions(linewidth=140, sci_mode=False, edgeitems=7)\n","pd.set_option('display.width', 140)"]},{"cell_type":"markdown","metadata":{"heading_collapsed":true},"source":["## Cleaning the data"]},{"cell_type":"markdown","metadata":{"hidden":true},"source":["This is a *tabular data* competition -- the data is in the form of a table. It's provided as a Comma Separated Values (CSV) file. We can open it using the *pandas* library, which will create a `DataFrame`."]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:34:17.899238Z","iopub.status.busy":"2022-05-30T22:34:17.898249Z","iopub.status.idle":"2022-05-30T22:34:17.932714Z","shell.execute_reply":"2022-05-30T22:34:17.931738Z","shell.execute_reply.started":"2022-05-30T22:34:17.899131Z"},"hidden":true,"scrolled":true,"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>male</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>A/5 21171</td>\n","      <td>7.2500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n","      <td>female</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>PC 17599</td>\n","      <td>71.2833</td>\n","      <td>C85</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>Heikkinen, Miss. Laina</td>\n","      <td>female</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>STON/O2. 3101282</td>\n","      <td>7.9250</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n","      <td>female</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113803</td>\n","      <td>53.1000</td>\n","      <td>C123</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Allen, Mr. William Henry</td>\n","      <td>male</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>373450</td>\n","      <td>8.0500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>886</th>\n","      <td>887</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>Montvila, Rev. Juozas</td>\n","      <td>male</td>\n","      <td>27.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>211536</td>\n","      <td>13.0000</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>887</th>\n","      <td>888</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Graham, Miss. Margaret Edith</td>\n","      <td>female</td>\n","      <td>19.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>112053</td>\n","      <td>30.0000</td>\n","      <td>B42</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>888</th>\n","      <td>889</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n","      <td>female</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>W./C. 6607</td>\n","      <td>23.4500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>889</th>\n","      <td>890</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Behr, Mr. Karl Howell</td>\n","      <td>male</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>111369</td>\n","      <td>30.0000</td>\n","      <td>C148</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>890</th>\n","      <td>891</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Dooley, Mr. Patrick</td>\n","      <td>male</td>\n","      <td>32.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>370376</td>\n","      <td>7.7500</td>\n","      <td>NaN</td>\n","      <td>Q</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>891 rows Ã— 12 columns</p>\n","</div>"],"text/plain":["     PassengerId  Survived  Pclass                                               Name     Sex   Age  SibSp  Parch            Ticket  \\\n","0              1         0       3                            Braund, Mr. Owen Harris    male  22.0      1      0         A/5 21171   \n","1              2         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1      0          PC 17599   \n","2              3         1       3                             Heikkinen, Miss. Laina  female  26.0      0      0  STON/O2. 3101282   \n","3              4         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1      0            113803   \n","4              5         0       3                           Allen, Mr. William Henry    male  35.0      0      0            373450   \n","..           ...       ...     ...                                                ...     ...   ...    ...    ...               ...   \n","886          887         0       2                              Montvila, Rev. Juozas    male  27.0      0      0            211536   \n","887          888         1       1                       Graham, Miss. Margaret Edith  female  19.0      0      0            112053   \n","888          889         0       3           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1      2        W./C. 6607   \n","889          890         1       1                              Behr, Mr. Karl Howell    male  26.0      0      0            111369   \n","890          891         0       3                                Dooley, Mr. Patrick    male  32.0      0      0            370376   \n","\n","        Fare Cabin Embarked  \n","0     7.2500   NaN        S  \n","1    71.2833   C85        C  \n","2     7.9250   NaN        S  \n","3    53.1000  C123        S  \n","4     8.0500   NaN        S  \n","..       ...   ...      ...  \n","886  13.0000   NaN        S  \n","887  30.0000   B42        S  \n","888  23.4500   NaN        S  \n","889  30.0000  C148        C  \n","890   7.7500   NaN        Q  \n","\n","[891 rows x 12 columns]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv(path/'train.csv')\n","df"]},{"cell_type":"markdown","metadata":{"hidden":true},"source":["As we learned in the *How does a neural net really work* notebook, we going to want to multiply each column by some coefficients. But we can see in the `Cabin` column that there are `NaN` values, which is how Pandas refers to missing values. We can't multiply something by a missing value!\n","\n","Let's check which columns contain `NaN` values. Pandas' `isna()` function returns `True` (which is treated as `1` when used as a number) for `NaN` values, so we can just add them up for each column:"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:34:17.955557Z","iopub.status.busy":"2022-05-30T22:34:17.95524Z","iopub.status.idle":"2022-05-30T22:34:17.966199Z","shell.execute_reply":"2022-05-30T22:34:17.96534Z","shell.execute_reply.started":"2022-05-30T22:34:17.955525Z"},"hidden":true,"trusted":true},"outputs":[{"data":{"text/plain":["PassengerId      0\n","Survived         0\n","Pclass           0\n","Name             0\n","Sex              0\n","Age            177\n","SibSp            0\n","Parch            0\n","Ticket           0\n","Fare             0\n","Cabin          687\n","Embarked         2\n","dtype: int64"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df.isna().sum()"]},{"cell_type":"markdown","metadata":{"hidden":true},"source":["Notice that by default Pandas sums over columns.\n","\n","We'll need to replace the missing values with something. It doesn't generally matter too much what we choose. We'll use the most common value (the \"*mode*\"). We can use the `mode` function for that. One wrinkle is that it returns more than one row in the case of ties, so we just grab the first row with `iloc[0]`:"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:34:18.012387Z","iopub.status.busy":"2022-05-30T22:34:18.011876Z","iopub.status.idle":"2022-05-30T22:34:18.030165Z","shell.execute_reply":"2022-05-30T22:34:18.029316Z","shell.execute_reply.started":"2022-05-30T22:34:18.012338Z"},"hidden":true,"trusted":true},"outputs":[{"data":{"text/plain":["PassengerId                      1\n","Survived                       0.0\n","Pclass                         3.0\n","Name           Abbing, Mr. Anthony\n","Sex                           male\n","Age                           24.0\n","SibSp                          0.0\n","Parch                          0.0\n","Ticket                        1601\n","Fare                          8.05\n","Cabin                      B96 B98\n","Embarked                         S\n","Name: 0, dtype: object"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["modes = df.mode().iloc[0]\n","modes"]},{"cell_type":"markdown","metadata":{"hidden":true},"source":["BTW, it's never a good idea to use functions without understanding them. So be sure to google for anything you're not familiar with. E.g if you want to learn about `iloc` (which is a very important function indeed!) then Google will give you a link to a [great tutorial](https://www.shanelynn.ie/pandas-iloc-loc-select-rows-and-columns-dataframe/).\n","\n","Now that we've got the mode of each column, we can use `fillna` to replace the missing values with the mode of each column. We'll do it \"in place\" -- meaning that we'll change the dataframe itself, rather than returning a new one."]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:34:18.069624Z","iopub.status.busy":"2022-05-30T22:34:18.069123Z","iopub.status.idle":"2022-05-30T22:34:18.078805Z","shell.execute_reply":"2022-05-30T22:34:18.077978Z","shell.execute_reply.started":"2022-05-30T22:34:18.069573Z"},"hidden":true,"trusted":true},"outputs":[],"source":["df.fillna(modes, inplace=True)"]},{"cell_type":"markdown","metadata":{"hidden":true},"source":["We can now check there's no missing values left:"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:34:18.139844Z","iopub.status.busy":"2022-05-30T22:34:18.13936Z","iopub.status.idle":"2022-05-30T22:34:18.149896Z","shell.execute_reply":"2022-05-30T22:34:18.148884Z","shell.execute_reply.started":"2022-05-30T22:34:18.139793Z"},"hidden":true,"trusted":true},"outputs":[{"data":{"text/plain":["PassengerId    0\n","Survived       0\n","Pclass         0\n","Name           0\n","Sex            0\n","Age            0\n","SibSp          0\n","Parch          0\n","Ticket         0\n","Fare           0\n","Cabin          0\n","Embarked       0\n","dtype: int64"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["df.isna().sum()"]},{"cell_type":"markdown","metadata":{"hidden":true},"source":["Here's how we get a quick summary of all the numeric columns in the dataset:"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:34:18.205953Z","iopub.status.busy":"2022-05-30T22:34:18.205483Z","iopub.status.idle":"2022-05-30T22:34:18.240196Z","shell.execute_reply":"2022-05-30T22:34:18.239106Z","shell.execute_reply.started":"2022-05-30T22:34:18.205897Z"},"hidden":true,"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Fare</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","      <td>891.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>446.000000</td>\n","      <td>0.383838</td>\n","      <td>2.308642</td>\n","      <td>28.566970</td>\n","      <td>0.523008</td>\n","      <td>0.381594</td>\n","      <td>32.204208</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>257.353842</td>\n","      <td>0.486592</td>\n","      <td>0.836071</td>\n","      <td>13.199572</td>\n","      <td>1.102743</td>\n","      <td>0.806057</td>\n","      <td>49.693429</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>1.000000</td>\n","      <td>0.420000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>223.500000</td>\n","      <td>0.000000</td>\n","      <td>2.000000</td>\n","      <td>22.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>7.910400</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>446.000000</td>\n","      <td>0.000000</td>\n","      <td>3.000000</td>\n","      <td>24.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>14.454200</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>668.500000</td>\n","      <td>1.000000</td>\n","      <td>3.000000</td>\n","      <td>35.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>31.000000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>891.000000</td>\n","      <td>1.000000</td>\n","      <td>3.000000</td>\n","      <td>80.000000</td>\n","      <td>8.000000</td>\n","      <td>6.000000</td>\n","      <td>512.329200</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       PassengerId    Survived      Pclass         Age       SibSp       Parch        Fare\n","count   891.000000  891.000000  891.000000  891.000000  891.000000  891.000000  891.000000\n","mean    446.000000    0.383838    2.308642   28.566970    0.523008    0.381594   32.204208\n","std     257.353842    0.486592    0.836071   13.199572    1.102743    0.806057   49.693429\n","min       1.000000    0.000000    1.000000    0.420000    0.000000    0.000000    0.000000\n","25%     223.500000    0.000000    2.000000   22.000000    0.000000    0.000000    7.910400\n","50%     446.000000    0.000000    3.000000   24.000000    0.000000    0.000000   14.454200\n","75%     668.500000    1.000000    3.000000   35.000000    1.000000    0.000000   31.000000\n","max     891.000000    1.000000    3.000000   80.000000    8.000000    6.000000  512.329200"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["import numpy as np\n","\n","df.describe(include=(np.number))"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2022-05-13T11:02:34.328433Z","iopub.status.busy":"2022-05-13T11:02:34.327999Z","iopub.status.idle":"2022-05-13T11:02:34.336993Z","shell.execute_reply":"2022-05-13T11:02:34.335466Z","shell.execute_reply.started":"2022-05-13T11:02:34.32838Z"},"hidden":true},"source":["We can see that `Fare` contains mainly values of around `0` to `30`, but there's a few really big ones. This is very common with fields contain monetary values, and it can cause problems for our model, because once that column is multiplied by a coefficient later, the few rows with really big values will dominate the result.\n","\n","You can see the issue most clearly visually by looking at a histogram, which shows a long tail to the right (and don't forget: if you're not entirely sure what a histogram is, Google \"[histogram tutorial](https://www.google.com/search?q=histogram+tutorial&oq=histogram+tutorial)\" and do a bit of reading before continuing on):"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:34:18.242123Z","iopub.status.busy":"2022-05-30T22:34:18.241874Z","iopub.status.idle":"2022-05-30T22:34:18.471439Z","shell.execute_reply":"2022-05-30T22:34:18.470441Z","shell.execute_reply.started":"2022-05-30T22:34:18.242094Z"},"hidden":true,"trusted":true},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["df['Fare'].hist();"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2022-05-13T11:02:34.328433Z","iopub.status.busy":"2022-05-13T11:02:34.327999Z","iopub.status.idle":"2022-05-13T11:02:34.336993Z","shell.execute_reply":"2022-05-13T11:02:34.335466Z","shell.execute_reply.started":"2022-05-13T11:02:34.32838Z"},"hidden":true},"source":["To fix this, the most common approach is to take the logarithm, which squishes the big numbers and makes the distribution more reasonable. Note, however, that there are zeros in the `Fare` column, and `log(0)` is infinite -- to fix this, we'll simply add `1` to all values first:"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:34:18.47382Z","iopub.status.busy":"2022-05-30T22:34:18.473109Z","iopub.status.idle":"2022-05-30T22:34:18.478776Z","shell.execute_reply":"2022-05-30T22:34:18.478149Z","shell.execute_reply.started":"2022-05-30T22:34:18.473778Z"},"hidden":true,"trusted":true},"outputs":[],"source":["df['LogFare'] = np.log(df['Fare']+1)"]},{"cell_type":"markdown","metadata":{"hidden":true},"source":["The histogram now shows a more even distribution of values without the long tail:"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:34:18.480926Z","iopub.status.busy":"2022-05-30T22:34:18.480088Z","iopub.status.idle":"2022-05-30T22:34:18.855605Z","shell.execute_reply":"2022-05-30T22:34:18.854915Z","shell.execute_reply.started":"2022-05-30T22:34:18.480885Z"},"hidden":true,"trusted":true},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["df['LogFare'].hist();"]},{"cell_type":"markdown","metadata":{"hidden":true},"source":["It looks from the `describe()` output like `Pclass` contains just 3 values, which we can confirm by looking at the [Data Dictionary](https://www.kaggle.com/competitions/titanic/data) (which you should always study carefully for any project!) -- "]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:34:18.857676Z","iopub.status.busy":"2022-05-30T22:34:18.857312Z","iopub.status.idle":"2022-05-30T22:34:18.863672Z","shell.execute_reply":"2022-05-30T22:34:18.862791Z","shell.execute_reply.started":"2022-05-30T22:34:18.857643Z"},"hidden":true,"trusted":true},"outputs":[{"data":{"text/plain":["[1, 2, 3]"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["pclasses = sorted(df.Pclass.unique())\n","pclasses"]},{"cell_type":"markdown","metadata":{"hidden":true},"source":["Here's how we get a quick summary of all the non-numeric columns in the dataset:"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:34:18.865154Z","iopub.status.busy":"2022-05-30T22:34:18.864893Z","iopub.status.idle":"2022-05-30T22:34:18.89758Z","shell.execute_reply":"2022-05-30T22:34:18.896706Z","shell.execute_reply.started":"2022-05-30T22:34:18.865115Z"},"hidden":true,"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Ticket</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>891</td>\n","      <td>891</td>\n","      <td>891</td>\n","      <td>891</td>\n","      <td>891</td>\n","    </tr>\n","    <tr>\n","      <th>unique</th>\n","      <td>891</td>\n","      <td>2</td>\n","      <td>681</td>\n","      <td>147</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>top</th>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>male</td>\n","      <td>347082</td>\n","      <td>B96 B98</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>freq</th>\n","      <td>1</td>\n","      <td>577</td>\n","      <td>7</td>\n","      <td>691</td>\n","      <td>646</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                           Name   Sex  Ticket    Cabin Embarked\n","count                       891   891     891      891      891\n","unique                      891     2     681      147        3\n","top     Braund, Mr. Owen Harris  male  347082  B96 B98        S\n","freq                          1   577       7      691      646"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["df.describe(include=[object])"]},{"cell_type":"markdown","metadata":{"hidden":true},"source":["Clearly we can't multiply strings like `male` or `S` by coefficients, so we need to replace those with numbers.\n","\n","We do that by creating new columns containing *dummy variables*. A dummy variable is a column that contains a `1` where a particular column contains a particular value, or a `0` otherwise. For instance, we could create a dummy variable for `Sex='male'`, which would be a new column containing `1` for rows where `Sex` is `'male'`, and 0 for rows where it isn't.\n","\n","Pandas can create these automatically using `get_dummies`, which also remove the original columns. We'll create dummy variables for `Pclass`, even although it's numeric, since the numbers `1`, `2`, and `3` correspond to first, second, and third class cabins - not to counts or measures that make sense to multiply by. We'll also create dummies for `Sex` and `Embarked` since we'll want to use those as predictors in our model. On the other hand, `Cabin`, `Name`, and `Ticket` have too many unique values for it to make sense creating dummy variables for them."]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:34:18.899369Z","iopub.status.busy":"2022-05-30T22:34:18.899127Z","iopub.status.idle":"2022-05-30T22:34:18.914993Z","shell.execute_reply":"2022-05-30T22:34:18.914167Z","shell.execute_reply.started":"2022-05-30T22:34:18.899338Z"},"hidden":true,"trusted":true},"outputs":[{"data":{"text/plain":["Index(['PassengerId', 'Survived', 'Name', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'LogFare', 'Sex_female', 'Sex_male',\n","       'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q', 'Embarked_S'],\n","      dtype='object')"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.get_dummies(df, columns=[\"Sex\",\"Pclass\",\"Embarked\"])\n","df.columns"]},{"cell_type":"markdown","metadata":{"hidden":true},"source":["We can see that 5 columns have been added to the end -- one for each of the possible values of each of the three columns we requested, and that those three requested columns have been removed.\n","\n","Here's what the first few rows of those newly added columns look like:"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:34:18.916456Z","iopub.status.busy":"2022-05-30T22:34:18.916186Z","iopub.status.idle":"2022-05-30T22:34:18.933746Z","shell.execute_reply":"2022-05-30T22:34:18.933135Z","shell.execute_reply.started":"2022-05-30T22:34:18.916426Z"},"hidden":true,"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sex_male</th>\n","      <th>Sex_female</th>\n","      <th>Pclass_1</th>\n","      <th>Pclass_2</th>\n","      <th>Pclass_3</th>\n","      <th>Embarked_C</th>\n","      <th>Embarked_Q</th>\n","      <th>Embarked_S</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Sex_male  Sex_female  Pclass_1  Pclass_2  Pclass_3  Embarked_C  Embarked_Q  Embarked_S\n","0      True       False     False     False      True       False       False        True\n","1     False        True      True     False     False        True       False       False\n","2     False        True     False     False      True       False       False        True\n","3     False        True      True     False     False       False       False        True\n","4      True       False     False     False      True       False       False        True"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["added_cols = ['Sex_male', 'Sex_female', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q', 'Embarked_S']\n","df[added_cols].head()"]},{"cell_type":"markdown","metadata":{"hidden":true},"source":["Now we can create our independent (predictors) and dependent (target) variables. They both need to be PyTorch tensors. Our dependent variable is `Survived`:"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:34:18.935422Z","iopub.status.busy":"2022-05-30T22:34:18.934648Z","iopub.status.idle":"2022-05-30T22:34:18.944596Z","shell.execute_reply":"2022-05-30T22:34:18.943444Z","shell.execute_reply.started":"2022-05-30T22:34:18.935384Z"},"hidden":true,"trusted":true},"outputs":[],"source":["from torch import tensor\n","\n","t_dep = tensor(df.Survived)"]},{"cell_type":"markdown","metadata":{"hidden":true},"source":["Our independent variables are all the continuous variables of interest plus all the dummy variables we just created:"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:34:18.946772Z","iopub.status.busy":"2022-05-30T22:34:18.94652Z","iopub.status.idle":"2022-05-30T22:34:18.96487Z","shell.execute_reply":"2022-05-30T22:34:18.963667Z","shell.execute_reply.started":"2022-05-30T22:34:18.946741Z"},"hidden":true,"trusted":true},"outputs":[{"data":{"text/plain":["tensor([[22.0000,  1.0000,  0.0000,  2.1102,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n","        [38.0000,  1.0000,  0.0000,  4.2806,  0.0000,  1.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n","        [26.0000,  0.0000,  0.0000,  2.1889,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n","        [35.0000,  1.0000,  0.0000,  3.9908,  0.0000,  1.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n","        [35.0000,  0.0000,  0.0000,  2.2028,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n","        [24.0000,  0.0000,  0.0000,  2.2469,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000],\n","        [54.0000,  0.0000,  0.0000,  3.9677,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n","        ...,\n","        [25.0000,  0.0000,  0.0000,  2.0857,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n","        [39.0000,  0.0000,  5.0000,  3.4054,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000],\n","        [27.0000,  0.0000,  0.0000,  2.6391,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n","        [19.0000,  0.0000,  0.0000,  3.4340,  0.0000,  1.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000],\n","        [24.0000,  1.0000,  2.0000,  3.1966,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000],\n","        [26.0000,  0.0000,  0.0000,  3.4340,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000],\n","        [32.0000,  0.0000,  0.0000,  2.1691,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  1.0000,  0.0000]])"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["indep_cols = ['Age', 'SibSp', 'Parch', 'LogFare'] + added_cols\n","df[added_cols] = df[added_cols].astype(float)\n","'''æ‰€é€‰åˆ—çš„æ•°æ®ç±»åž‹è½¬æ¢ä¸ºæµ®ç‚¹æ•°ç±»åž‹ (float)'''\n","t_indep = tensor(df[indep_cols].values, dtype=torch.float)\n","t_indep"]},{"cell_type":"markdown","metadata":{"hidden":true},"source":["Here's the number of rows and columns we have for our independent variables:"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:34:18.969136Z","iopub.status.busy":"2022-05-30T22:34:18.968005Z","iopub.status.idle":"2022-05-30T22:34:18.98114Z","shell.execute_reply":"2022-05-30T22:34:18.980184Z","shell.execute_reply.started":"2022-05-30T22:34:18.969092Z"},"hidden":true,"trusted":true},"outputs":[{"data":{"text/plain":["torch.Size([891, 12])"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["t_indep.shape"]},{"cell_type":"markdown","metadata":{},"source":["## Setting up a linear model"]},{"cell_type":"markdown","metadata":{},"source":["Now that we've got a matrix of independent variables and a dependent variable vector, we can work on calculating our predictions and our loss. In this section, we're going to manually do a single step of calculating predictions and loss for every row of our data.\n","\n","Our first model will be a simple linear model. We'll need a coefficient for each column in `t_indep`. We'll pick random numbers in the range `(-0.5,0.5)`, and set our manual seed so that my explanations in the prose in this notebook will be consistent with what you see when you run it."]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:34:18.983237Z","iopub.status.busy":"2022-05-30T22:34:18.982492Z","iopub.status.idle":"2022-05-30T22:34:18.995038Z","shell.execute_reply":"2022-05-30T22:34:18.994437Z","shell.execute_reply.started":"2022-05-30T22:34:18.983187Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([-0.4629,  0.1386,  0.2409, -0.2262, -0.2632, -0.3147,  0.4876,  0.3136,  0.2799, -0.4392,  0.2103,  0.3625])"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["torch.manual_seed(442)\n","\n","n_coeff = t_indep.shape[1]\n","coeffs = torch.rand(n_coeff)-0.5\n","coeffs"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([-0.4629,  0.1386,  0.2409, -0.2262, -0.2632, -0.3147,  0.4876,  0.3136,  0.2799, -0.4392,  0.2103,  0.3625])"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["torch.manual_seed(442)\n","n_coeff = t_indep.shape[1]\n","coeffs = torch.rand(n_coeff)-0.5\n","coeffs"]},{"cell_type":"markdown","metadata":{},"source":["Our predictions will be calculated by multiplying each row by the coefficients, and adding them up. One interesting point here is that we don't need a separate constant term (also known as a \"bias\" or \"intercept\" term), or a column of all `1`s to give the same effect has having a constant term. That's because our dummy variables already cover the entire dataset -- e.g. there's a column for \"male\" and a column for \"female\", and everyone in the dataset is in exactly one of these; therefore, we don't need a separate intercept term to cover rows that aren't otherwise part of a column.\n","\n","Here's what the multiplication looks like:"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:34:19.000637Z","iopub.status.busy":"2022-05-30T22:34:18.999409Z","iopub.status.idle":"2022-05-30T22:34:19.009362Z","shell.execute_reply":"2022-05-30T22:34:19.00847Z","shell.execute_reply.started":"2022-05-30T22:34:19.000588Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([[-10.1838,   0.1386,   0.0000,  -0.4772,  -0.2632,  -0.0000,   0.0000,   0.0000,   0.2799,  -0.0000,   0.0000,   0.3625],\n","        [-17.5902,   0.1386,   0.0000,  -0.9681,  -0.0000,  -0.3147,   0.4876,   0.0000,   0.0000,  -0.4392,   0.0000,   0.0000],\n","        [-12.0354,   0.0000,   0.0000,  -0.4950,  -0.0000,  -0.3147,   0.0000,   0.0000,   0.2799,  -0.0000,   0.0000,   0.3625],\n","        [-16.2015,   0.1386,   0.0000,  -0.9025,  -0.0000,  -0.3147,   0.4876,   0.0000,   0.0000,  -0.0000,   0.0000,   0.3625],\n","        [-16.2015,   0.0000,   0.0000,  -0.4982,  -0.2632,  -0.0000,   0.0000,   0.0000,   0.2799,  -0.0000,   0.0000,   0.3625],\n","        [-11.1096,   0.0000,   0.0000,  -0.5081,  -0.2632,  -0.0000,   0.0000,   0.0000,   0.2799,  -0.0000,   0.2103,   0.0000],\n","        [-24.9966,   0.0000,   0.0000,  -0.8973,  -0.2632,  -0.0000,   0.4876,   0.0000,   0.0000,  -0.0000,   0.0000,   0.3625],\n","        ...,\n","        [-11.5725,   0.0000,   0.0000,  -0.4717,  -0.2632,  -0.0000,   0.0000,   0.0000,   0.2799,  -0.0000,   0.0000,   0.3625],\n","        [-18.0531,   0.0000,   1.2045,  -0.7701,  -0.0000,  -0.3147,   0.0000,   0.0000,   0.2799,  -0.0000,   0.2103,   0.0000],\n","        [-12.4983,   0.0000,   0.0000,  -0.5968,  -0.2632,  -0.0000,   0.0000,   0.3136,   0.0000,  -0.0000,   0.0000,   0.3625],\n","        [ -8.7951,   0.0000,   0.0000,  -0.7766,  -0.0000,  -0.3147,   0.4876,   0.0000,   0.0000,  -0.0000,   0.0000,   0.3625],\n","        [-11.1096,   0.1386,   0.4818,  -0.7229,  -0.0000,  -0.3147,   0.0000,   0.0000,   0.2799,  -0.0000,   0.0000,   0.3625],\n","        [-12.0354,   0.0000,   0.0000,  -0.7766,  -0.2632,  -0.0000,   0.4876,   0.0000,   0.0000,  -0.4392,   0.0000,   0.0000],\n","        [-14.8128,   0.0000,   0.0000,  -0.4905,  -0.2632,  -0.0000,   0.0000,   0.0000,   0.2799,  -0.0000,   0.2103,   0.0000]])"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["t_indep*coeffs"]},{"cell_type":"markdown","metadata":{},"source":["We can see we've got a problem here. The sums of each row will be dominated by the first column, which is `Age`, since that's bigger on average than all the others.\n","\n","Let's make all the columns contain numbers from `0` to `1`, by dividing each column by its `max()`:"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/plain":["(tensor([80.0000,  8.0000,  6.0000,  6.2409,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000,  1.0000]),\n"," tensor([630, 159, 678, 258,   0,   1,   1,   9,   0,   1,   5,   0]))"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["vals,indices = t_indep.max(dim=0)\n","vals,indices"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:34:19.011202Z","iopub.status.busy":"2022-05-30T22:34:19.010954Z","iopub.status.idle":"2022-05-30T22:34:19.02202Z","shell.execute_reply":"2022-05-30T22:34:19.02133Z","shell.execute_reply.started":"2022-05-30T22:34:19.011171Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([[0.2750, 0.1250, 0.0000, 0.3381, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000],\n","        [0.4750, 0.1250, 0.0000, 0.6859, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000],\n","        [0.3250, 0.0000, 0.0000, 0.3507, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000],\n","        [0.4375, 0.1250, 0.0000, 0.6395, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n","        [0.4375, 0.0000, 0.0000, 0.3530, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000],\n","        [0.3000, 0.0000, 0.0000, 0.3600, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000],\n","        [0.6750, 0.0000, 0.0000, 0.6358, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n","        ...,\n","        [0.3125, 0.0000, 0.0000, 0.3342, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000],\n","        [0.4875, 0.0000, 0.8333, 0.5456, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000],\n","        [0.3375, 0.0000, 0.0000, 0.4229, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n","        [0.2375, 0.0000, 0.0000, 0.5502, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000],\n","        [0.3000, 0.1250, 0.3333, 0.5122, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000],\n","        [0.3250, 0.0000, 0.0000, 0.5502, 1.0000, 0.0000, 1.0000, 0.0000, 0.0000, 1.0000, 0.0000, 0.0000],\n","        [0.4000, 0.0000, 0.0000, 0.3476, 1.0000, 0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 0.0000]])"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["vals,indices = t_indep.max(dim=0)\n","t_indep = t_indep / vals\n","t_indep"]},{"cell_type":"markdown","metadata":{},"source":["As we see, that removes the problem of one column dominating all the others:"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:34:19.04269Z","iopub.status.busy":"2022-05-30T22:34:19.042223Z","iopub.status.idle":"2022-05-30T22:34:19.050475Z","shell.execute_reply":"2022-05-30T22:34:19.049515Z","shell.execute_reply.started":"2022-05-30T22:34:19.042652Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([[-0.1273,  0.0173,  0.0000, -0.0765, -0.2632, -0.0000,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],\n","        [-0.2199,  0.0173,  0.0000, -0.1551, -0.0000, -0.3147,  0.4876,  0.0000,  0.0000, -0.4392,  0.0000,  0.0000],\n","        [-0.1504,  0.0000,  0.0000, -0.0793, -0.0000, -0.3147,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],\n","        [-0.2025,  0.0173,  0.0000, -0.1446, -0.0000, -0.3147,  0.4876,  0.0000,  0.0000, -0.0000,  0.0000,  0.3625],\n","        [-0.2025,  0.0000,  0.0000, -0.0798, -0.2632, -0.0000,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],\n","        [-0.1389,  0.0000,  0.0000, -0.0814, -0.2632, -0.0000,  0.0000,  0.0000,  0.2799, -0.0000,  0.2103,  0.0000],\n","        [-0.3125,  0.0000,  0.0000, -0.1438, -0.2632, -0.0000,  0.4876,  0.0000,  0.0000, -0.0000,  0.0000,  0.3625],\n","        ...,\n","        [-0.1447,  0.0000,  0.0000, -0.0756, -0.2632, -0.0000,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],\n","        [-0.2257,  0.0000,  0.2008, -0.1234, -0.0000, -0.3147,  0.0000,  0.0000,  0.2799, -0.0000,  0.2103,  0.0000],\n","        [-0.1562,  0.0000,  0.0000, -0.0956, -0.2632, -0.0000,  0.0000,  0.3136,  0.0000, -0.0000,  0.0000,  0.3625],\n","        [-0.1099,  0.0000,  0.0000, -0.1244, -0.0000, -0.3147,  0.4876,  0.0000,  0.0000, -0.0000,  0.0000,  0.3625],\n","        [-0.1389,  0.0173,  0.0803, -0.1158, -0.0000, -0.3147,  0.0000,  0.0000,  0.2799, -0.0000,  0.0000,  0.3625],\n","        [-0.1504,  0.0000,  0.0000, -0.1244, -0.2632, -0.0000,  0.4876,  0.0000,  0.0000, -0.4392,  0.0000,  0.0000],\n","        [-0.1852,  0.0000,  0.0000, -0.0786, -0.2632, -0.0000,  0.0000,  0.0000,  0.2799, -0.0000,  0.2103,  0.0000]])"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["t_indep*coeffs"]},{"cell_type":"markdown","metadata":{},"source":["One thing you hopefully noticed is how amazingly cool this line of code is:\n","\n","    t_indep = t_indep / vals\n","\n","That is dividing a matrix by a vector -- what on earth does that mean?!? The trick here is that we're taking advantage of a technique in numpy and PyTorch (and many other languages, going all the way back to APL) called [broadcasting](https://numpy.org/doc/stable/user/basics.broadcasting.html). In short, this acts as if there's a separate copy of the vector for every row of the matrix, so it divides each row of the matrix by the vector. In practice, it doesn't actually make any copies, and does the whole thing in a highly optimized way, taking full advantage of modern CPUs (or, indeed, GPUs, if we're using them). Broadcasting is one of the most important techniques for making your code concise, maintainable, and fast, so it's well worth studying and practicing.\n","\n","We can now create predictions from our linear model, by adding up the rows of the product:"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:34:19.097604Z","iopub.status.busy":"2022-05-30T22:34:19.096685Z","iopub.status.idle":"2022-05-30T22:34:19.1028Z","shell.execute_reply":"2022-05-30T22:34:19.10218Z","shell.execute_reply.started":"2022-05-30T22:34:19.097545Z"},"trusted":true},"outputs":[],"source":["preds = (t_indep*coeffs).sum(axis=1)"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"data":{"text/plain":["(891,\n"," tensor([     0.1927,     -0.6239,      0.0979,      0.2056,      0.0968,      0.0066,      0.1306,      0.3476,      0.1613,     -0.6285,\n","              0.2579,      0.0796,      0.1836,      0.2457,      0.1676,     -0.0595,      0.2014,      0.1783,      0.0589,     -0.6892,\n","              0.0909,      0.1205,      0.0089,      0.2945,      0.2614,      0.1999,     -0.6378,      0.4071,     -0.0425,      0.1611,\n","             -0.5679,     -0.5688,     -0.0420,     -0.0576,     -0.5197,      0.2173,     -0.6378,      0.1778,      0.1515,     -0.6284,\n","              0.0284,      0.1104,     -0.6406,     -0.4960,     -0.0136,      0.1605,      0.0038,     -0.0420,     -0.6399,      0.1345,\n","              0.3138,      0.1788,     -0.6902,      0.0915,     -0.7009,      0.3176,      0.1514,     -0.6638,      0.3084,      0.3422,\n","             -0.6262,      0.1563,      0.1831,      0.3664,     -0.4753,     -0.6049,      0.1051,      0.1890,      0.2996,      0.1812,\n","              0.1392,      0.2618,      0.1351,     -0.6549,      0.0472,      0.1563,      0.1611,      0.1605,      0.3651,      0.0598,\n","              0.1684,      0.1261,     -0.0422,      0.2845,      0.1745,      0.0864,      0.2951,      0.1605,      0.3325,      0.1605,\n","              0.1315,      0.1844,      0.1884,      0.2150,     -0.0387,      0.1605,     -0.7551,     -0.4586,      0.0896,      0.1140,\n","              0.0865,      0.1611,      0.3475,      0.1060,      0.1204,      0.1379,      0.1280,      0.1616,      0.0801,     -0.0630,\n","              0.1710,     -0.6398,      0.1720,      0.1430,     -0.6716,      0.1783,     -0.2596,      0.1503,     -0.5134,      0.3398,\n","              0.1698,      0.1605,     -0.6841,      0.0777,      0.1566,     -0.5654,      0.0095,      0.1643,     -0.6696,      0.0435,\n","             -0.6927,      0.1878,     -0.0263,      0.0915,      0.1725,     -0.6225,      0.3860,      0.2455,      0.2024,     -0.5126,\n","             -0.6336,      0.1218,      0.1038,      0.0428,      0.2172,      0.2288,      0.1441,      0.2613,      0.1625,      0.0742,\n","              0.0234,      0.2727,     -0.0218,      0.1258,      0.1635,     -0.6195,      0.0043,      0.1257,      0.1581,      0.3049,\n","              0.0618,      0.0278,      0.1500,      0.1986,      0.3485,      0.2962,      0.2908,      0.1233,      0.3287,      0.0703,\n","              0.1056,      0.1898,      0.2889,      0.1783,     -0.6641,      0.2534,      0.2137,     -0.6785,      0.1436,      0.1708,\n","              0.2535,     -0.6283,      0.3506,      0.3482,      0.2712,      0.3055,     -0.0477,      0.2063,     -0.0486,      0.0916,\n","              0.0806,      0.2073,      0.1560,      0.3335,     -0.6425,     -0.7828,      0.0095,      0.0951,     -0.0420,      0.1269,\n","              0.1319,      0.3049,      0.1094,     -0.7622,      0.1952,      0.2679,      0.1090,     -0.6811,      0.0043,     -0.5718,\n","              0.1647,      0.0468,      0.1754,      0.1436,      0.0268,     -0.6000,      0.0921,      0.0664,     -0.6090,      0.1507,\n","              0.2067,      0.1610,      0.0042,      0.1611,      0.2209,      0.1672,      0.2144,      0.1841,      0.2130,      0.1622,\n","              0.1894,      0.1326,     -0.0255,      0.3223,      0.1855,      0.1110,      0.0561,      0.2756,      0.2144,      0.1282,\n","             -0.6948,     -0.0477,      0.1565,      0.1759,     -0.6725,      0.0512,      0.1043,      0.2035,      0.2860,     -0.0017,\n","              0.1638,      0.1290,      0.1080,      0.1200,      0.0601,     -0.6625,     -0.5640,      0.1998,     -0.6949,     -0.0072,\n","              0.0095,      0.3854,      0.1844,      0.3554,     -0.0420,      0.1160,      0.2617,      0.1731,      0.0573,      0.1547,\n","              0.3224,      0.2345,      0.0548,     -0.5128,     -0.0420,      0.0299,     -0.0113,      0.2740,      0.1725,      0.0719,\n","             -0.2278,      0.1381,      0.2014,      0.1894,      0.3286,     -0.6957,      0.1204,      0.1727,      0.0742,     -0.0304,\n","              0.2262,     -0.5228,     -0.6925,      0.1059,      0.1611,     -0.4753,     -0.6349,      0.4393,      0.3230,     -0.7153,\n","             -0.0420,      0.0072,      0.2692,     -0.0236,      0.1605,      0.4970,     -0.5761,     -0.5176,     -0.6617,     -0.5869,\n","             -0.5658,     -0.4574,      0.1490,      0.1379,      0.1017,      0.0982,      0.1204,      0.0022,      0.2511,     -0.6181,\n","              0.1754,      0.1437,     -0.0584,      0.1683,      0.3049,     -0.6528,     -0.0455,      0.0574,      0.0946,     -0.4664,\n","             -0.0443,      0.2010,      0.2245,      0.2145,      0.2362,      0.1611,      0.2837,     -0.6814,      0.0389,      0.1961,\n","              0.3393,      0.3267,      0.1552,      0.1725,      0.1089,      0.1269,      0.0343,      0.1033,      0.3168,      0.0539,\n","              0.1618,      0.3181,     -0.5282,      0.1455,     -0.6378,      0.1319,      0.3024,      0.0459,     -0.0425,     -0.0425,\n","              0.2037,     -0.6610,     -0.7934,      0.1011,      0.0038,      0.1291,     -0.7532,     -0.6892,     -0.0420,     -0.5592,\n","             -0.4883,      0.2193,      0.1894,     -0.5203,      0.2903,     -0.5480,      0.1239,     -0.4849,     -0.5967,      0.1905,\n","             -0.7061,     -0.5016,      0.1147,      0.2063,      0.1611,      0.1525,      0.4001,      0.0574,      0.0095,     -0.6316,\n","              0.3024,      0.1788,      0.1725,     -0.5537,      0.1650,      0.1731,      0.0693,      0.0272,      0.1912,      0.1046,\n","              0.0742,      0.1489,      0.1372,      0.1321,      0.1298,      0.1214,      0.0054,      0.3448,      0.1789,      0.1622,\n","              0.1611,      0.0133,      0.0461,      0.2740,      0.0452,      0.1090,      0.0949,      0.2419,      0.1436,      0.2333,\n","             -0.6406,      0.0269,      0.1322,      0.1241,      0.2218,      0.1638,      0.0972,      0.1320,      0.0095,      0.1142,\n","              0.3047,      0.1033,      0.0162,      0.2049,      0.1684,      0.3782,      0.1919,      0.2695,      0.1924,      0.1450,\n","              0.0387,      0.1782,      0.1731,      0.1037,      0.1602,      0.4840,      0.2168,      0.2700,     -0.5372,      0.1610,\n","              0.1804,      0.1473,     -0.5101,     -0.6441,      0.1605,     -0.6695,      0.0906,      0.2701,     -0.0164,      0.0095,\n","              0.1890,      0.1026,      0.1817,      0.0395,      0.1605,      0.0837,      0.2740,      0.1427,      0.0096,     -0.5126,\n","              0.1638,      0.0771,      0.1463,     -0.6710,      0.1140,      0.3041,      0.1214,      0.1531,      0.1742,      0.2625,\n","              0.3538,      0.2740,      0.0100,     -0.1224,     -0.5060,      0.1622,      0.1867,     -0.6745,      0.1257,      0.2821,\n","              0.1473,      0.1812,      0.1436,     -0.7677,      0.1778,     -0.6606,     -0.7199,      0.1396,      0.3062,      0.1615,\n","              0.1986,     -0.0247,     -0.0415,      0.0281,      0.2808,     -0.4719,      0.1313,      0.3278,      0.1027,      0.0819,\n","             -0.0195,      0.1605,      0.2588,     -0.7100,      0.1627,      0.1861,      0.0761,     -0.0288,      0.0510,      0.1148,\n","              0.1970,      0.1727,     -0.6378,     -0.6285,     -0.6378,     -0.0860,     -0.0164,      0.2521,      0.0742,      0.2630,\n","              0.2878,     -0.6378,     -0.5398,     -0.6467,      0.0719,      0.2814,      0.2063,     -0.6093,      0.1410,     -0.4554,\n","              0.2524,      0.2993,      0.2877,      0.1256,     -0.6563,      0.0971,      0.1493,     -0.6255,      0.1345,      0.2924,\n","             -0.4038,      0.1372,      0.0091,     -0.6262,      0.1217,      0.1080,     -0.6609,     -0.5505,      0.2081,      0.0312,\n","              0.0095,      0.0685,      0.1539,      0.1605,      0.1090,      0.1581,      0.1900,      0.2083,     -0.6378,      0.1150,\n","             -0.0344,      0.1199,      0.2586,     -0.0420,      0.2067,      0.1699,      0.0690,      0.1806,     -0.6948,      0.1147,\n","              0.1497,     -0.6054,     -0.0191,     -0.5578,     -0.6438,      0.3525,      0.0404,     -0.6634,      0.1720,      0.1605,\n","              0.1007,     -0.7083,      0.0307,      0.0383,      0.0966,      0.1115,      0.0947,      0.0956,     -0.6378,     -0.6281,\n","              0.1765,      0.1611,      0.3114,      0.0447,     -0.5375,      0.0865,      0.1264,      0.3056,     -0.6059,      0.1213,\n","              0.1942,      0.1647,     -0.0477,      0.0095,      0.0968,      0.1683,      0.1408,      0.0917,      0.2793,      0.1739,\n","             -0.6606,      0.2169,     -0.5829,      0.1786,      0.1548,      0.1069,     -0.1631,      0.2556,      0.1495,      0.0095,\n","             -0.0005,      0.0085,     -0.5250,      0.4480,      0.2860,      0.1037,      0.1147,      0.1712,      0.1569,      0.1547,\n","              0.1844,     -0.5592,      0.3265,      0.0935,     -0.5126,     -0.6330,      0.1900,     -0.6692,      0.1625,      0.1168,\n","              0.1611,      0.1822,      0.1763,     -0.0423,     -0.0029,      0.1524,      0.1611,     -0.0538,      0.1841,     -0.6418,\n","              0.1545,     -0.7303,      0.1960,      0.0933,      0.2014,      0.1061,      0.1725,      0.1616,      0.0505,      0.2700,\n","              0.0537,      0.2810,     -0.0807,      0.1378,      0.2740,      0.1963,      0.1576,      0.1372,      0.1969,     -0.6091,\n","             -0.0436,     -0.5288,      0.1792,      0.3248,     -0.0105,     -0.5718,      0.2733,      0.1818,      0.1962,      0.2946,\n","              0.2777,     -0.5537,      0.0935,     -0.6435,      0.1195,      0.0150,      0.0447,     -0.0419,     -0.6118,      0.0579,\n","             -0.5499,      0.2645,     -0.6372,      0.0037,      0.1670,      0.0677,      0.0041,      0.2240,      0.2259,     -0.6049,\n","             -0.5473,      0.3278,      0.1826,      0.1262,      0.0163,      0.1910,     -0.6830,      0.1166,     -0.0135,      0.1095,\n","              0.2390,      0.2225,      0.1205,      0.0279,      0.3034,      0.1812,      0.1277,     -0.0420,      0.1661,      0.1210,\n","              0.1734,     -0.5943,      0.2740,      0.1841,      0.1841,      0.1114,      0.0585,     -0.6435,      0.1611,      0.1611,\n","              0.3236,      0.2372,     -0.4748,      0.1547,      0.1205,      0.0843,      0.2333,      0.0921,      0.3496,     -0.0311,\n","              0.2805,      0.2903,      0.1030,      0.1669,      0.0294,      0.3671,      0.1383,      0.2172,      0.1026,      0.1824,\n","              0.1410,      0.0660,     -0.6146,      0.2509,      0.2079,      0.0993,     -0.4879,     -0.0796,     -0.0115,      0.1129,\n","              0.1551,      0.0224,     -0.0570,     -0.6378,      0.0715,      0.1964,      0.0095,      0.2045,      0.0095,      0.1326,\n","             -0.6256,      0.3072,      0.2946,      0.2221,      0.1589,      0.1580,      0.1460,      0.1667,      0.3597,     -0.6398,\n","              0.0095,      0.2008,      0.2535,     -0.4789,      0.1553,      0.0915,      0.1325,      0.0660,     -0.6725,      0.0947,\n","              0.1205,      0.1197,      0.4471,     -0.4664,      0.1477,      0.1211,      0.3612,      0.1448,      0.0915,      0.2172,\n","              0.1495,      0.0366,      0.1218,      0.3167,      0.1228,      0.4480,      0.1153,     -0.6426,      0.0576,      0.3317,\n","              0.1272,      0.1407,      0.3670,      0.1174,      0.3427,      0.0129,      0.0935,     -0.4461,      0.0095,      0.0174,\n","             -0.6427,      0.3574,     -0.6378,      0.1670,      0.1942,     -0.5951,      0.1754,      0.1605,      0.0472,     -0.4778,\n","              0.1841,      0.2318,     -0.5654,     -0.6949,      0.1986,      0.0584,      0.3049,     -0.7042,      0.1632,     -0.5509,\n","              0.3797,     -0.1277,     -0.5696,      0.3489,      0.0047,      0.1790,      0.1473,      0.1716,     -0.6014,     -0.6378,\n","              0.0782,      0.2171,      0.1383,      0.2535,      0.1783,      0.0227,     -0.6770,      0.2647,      0.1551,      0.3230,\n","              0.1495,      0.1767,      0.3310,      0.0238,     -0.7016,     -0.6371,      0.1770,      0.1900,      0.1611,     -0.7108,\n","              0.1374,      0.1090,      0.1118,      0.1623,      0.1589,      0.0271,      0.1610,      0.3010,      0.1706,     -0.4897,\n","             -0.0368]))"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["preds = (t_indep*coeffs).sum(axis=1)\n","len(preds),preds"]},{"cell_type":"markdown","metadata":{},"source":["Let's take a look at the first few:"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:34:19.160794Z","iopub.status.busy":"2022-05-30T22:34:19.160318Z","iopub.status.idle":"2022-05-30T22:34:19.168117Z","shell.execute_reply":"2022-05-30T22:34:19.167355Z","shell.execute_reply.started":"2022-05-30T22:34:19.160761Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([ 0.1927, -0.6239,  0.0979,  0.2056,  0.0968,  0.0066,  0.1306,  0.3476,  0.1613, -0.6285])"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["preds[:10]"]},{"cell_type":"markdown","metadata":{},"source":["Of course, these predictions aren't going to be any use, since our coefficients are random -- they're just a starting point for our gradient descent process.\n","\n","To do gradient descent, we need a loss function. Taking the average error of the rows (i.e. the absolute value of the difference between the prediction and the dependent) is generally a reasonable approach:"]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"data":{"text/plain":["tensor(0.5382)"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["loss = torch.abs(preds-t_dep).mean()\n","loss"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:34:19.235623Z","iopub.status.busy":"2022-05-30T22:34:19.235318Z","iopub.status.idle":"2022-05-30T22:34:19.24312Z","shell.execute_reply":"2022-05-30T22:34:19.242356Z","shell.execute_reply.started":"2022-05-30T22:34:19.235589Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor(0.5382)"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["loss = torch.abs(preds-t_dep).mean()\n","loss"]},{"cell_type":"markdown","metadata":{},"source":["Now that we've tested out a way of calculating predictions, and loss, let's pop them into functions to make life easier:"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:34:19.296558Z","iopub.status.busy":"2022-05-30T22:34:19.295577Z","iopub.status.idle":"2022-05-30T22:34:19.301478Z","shell.execute_reply":"2022-05-30T22:34:19.300683Z","shell.execute_reply.started":"2022-05-30T22:34:19.296517Z"},"trusted":true},"outputs":[],"source":["def calc_preds(coeffs, indeps): return (indeps*coeffs).sum(axis=1)\n","def calc_loss(coeffs, indeps, deps): return torch.abs(calc_preds(coeffs, indeps)-deps).mean()"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["def calc_preds(coeffs,indeps): return (indeps*coeffs).sum(axis=1)\n","def calc_loss(coeffs,indeps,deps): return torch.abs(calc_preds(coeffs,indeps)-deps).mean()"]},{"cell_type":"markdown","metadata":{},"source":["## Doing a gradient descent step"]},{"cell_type":"markdown","metadata":{},"source":["In this section, we're going to do a single \"epoch\" of gradient descent manually. The only thing we're going to automate is calculating gradients, because let's face it that's pretty tedious and entirely pointless to do by hand! To get PyTorch to calculate gradients, we'll need to call `requires_grad_()` on our `coeffs` (if you're not sure why, review the previous notebook, [How does a neural net really work?](https://www.kaggle.com/code/jhoward/how-does-a-neural-net-really-work), before continuing):"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:34:19.376212Z","iopub.status.busy":"2022-05-30T22:34:19.375387Z","iopub.status.idle":"2022-05-30T22:34:19.382205Z","shell.execute_reply":"2022-05-30T22:34:19.381536Z","shell.execute_reply.started":"2022-05-30T22:34:19.376163Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([-0.4629,  0.1386,  0.2409, -0.2262, -0.2632, -0.3147,  0.4876,  0.3136,  0.2799, -0.4392,  0.2103,  0.3625], requires_grad=True)"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["coeffs.requires_grad_()"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"data":{"text/plain":["False"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["preds.requires_grad"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([-0.4629,  0.1386,  0.2409, -0.2262, -0.2632, -0.3147,  0.4876,  0.3136,  0.2799, -0.4392,  0.2103,  0.3625], requires_grad=True)"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["coeffs.requires_grad_()"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"data":{"text/plain":["' ä¼šæ˜¾ç¤ºå¸ƒå°”å€¼'"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["coeffs.requires_grad\n","''' ä¼šæ˜¾ç¤ºå¸ƒå°”å€¼'''"]},{"cell_type":"markdown","metadata":{},"source":["Now when we calculate our loss, PyTorch will keep track of all the steps, so we'll be able to get the gradients afterwards:"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:34:19.438026Z","iopub.status.busy":"2022-05-30T22:34:19.437208Z","iopub.status.idle":"2022-05-30T22:34:19.444641Z","shell.execute_reply":"2022-05-30T22:34:19.443791Z","shell.execute_reply.started":"2022-05-30T22:34:19.437985Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor(0.5382, grad_fn=<MeanBackward0>)"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["loss = calc_loss(coeffs, t_indep, t_dep)\n","loss"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"data":{"text/plain":["tensor(0.5382, grad_fn=<MeanBackward0>)"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["loss = calc_loss(coeffs,t_indep,t_dep)\n","loss"]},{"cell_type":"markdown","metadata":{},"source":["Use `backward()` to ask PyTorch to calculate gradients now:"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:34:19.49239Z","iopub.status.busy":"2022-05-30T22:34:19.491601Z","iopub.status.idle":"2022-05-30T22:34:19.496556Z","shell.execute_reply":"2022-05-30T22:34:19.495831Z","shell.execute_reply.started":"2022-05-30T22:34:19.492353Z"},"trusted":true},"outputs":[],"source":["loss.backward()"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[{"data":{"text/plain":["tensor(0.5382, grad_fn=<MeanBackward0>)"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["loss"]},{"cell_type":"markdown","metadata":{},"source":["Let's see what they look like:"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([-0.4629,  0.1386,  0.2409, -0.2262, -0.2632, -0.3147,  0.4876,  0.3136,  0.2799, -0.4392,  0.2103,  0.3625], requires_grad=True)"]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["coeffs"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:34:19.550501Z","iopub.status.busy":"2022-05-30T22:34:19.549651Z","iopub.status.idle":"2022-05-30T22:34:19.555905Z","shell.execute_reply":"2022-05-30T22:34:19.555257Z","shell.execute_reply.started":"2022-05-30T22:34:19.550456Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([-0.0106,  0.0129, -0.0041, -0.0484,  0.2099, -0.2132, -0.1212, -0.0247,  0.1425, -0.1886, -0.0191,  0.2043])"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["coeffs.grad"]},{"cell_type":"markdown","metadata":{},"source":["Note that each time we call `backward`, the gradients are actually *added* to whatever is in the `.grad` attribute. Let's try running the above steps again:"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:34:19.603236Z","iopub.status.busy":"2022-05-30T22:34:19.60283Z","iopub.status.idle":"2022-05-30T22:34:19.610594Z","shell.execute_reply":"2022-05-30T22:34:19.609647Z","shell.execute_reply.started":"2022-05-30T22:34:19.603206Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([-0.0212,  0.0258, -0.0082, -0.0969,  0.4198, -0.4265, -0.2424, -0.0494,  0.2851, -0.3771, -0.0382,  0.4085])"]},"execution_count":42,"metadata":{},"output_type":"execute_result"}],"source":["loss = calc_loss(coeffs, t_indep, t_dep)\n","loss.backward()\n","coeffs.grad"]},{"cell_type":"markdown","metadata":{},"source":["As you see, our `.grad` values are have doubled. That's because it added the gradients a second time. For this reason, after we use the gradients to do a gradient descent step, we need to set them back to zero.\n","\n","We can now do one gradient descent step, and check that our loss decreases:"]},{"cell_type":"code","execution_count":43,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:34:19.665739Z","iopub.status.busy":"2022-05-30T22:34:19.665238Z","iopub.status.idle":"2022-05-30T22:34:19.674839Z","shell.execute_reply":"2022-05-30T22:34:19.673727Z","shell.execute_reply.started":"2022-05-30T22:34:19.665705Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor(0.4945)\n"]}],"source":["loss = calc_loss(coeffs, t_indep, t_dep)\n","loss.backward()\n","with torch.no_grad():\n","    coeffs.sub_(coeffs.grad * 0.1)\n","    coeffs.grad.zero_()\n","    print(calc_loss(coeffs, t_indep, t_dep))"]},{"cell_type":"markdown","metadata":{},"source":["Note that `a.sub_(b)` subtracts `b` from `a` in-place. In PyTorch, any method that ends in `_` changes its object in-place. Similarly, `a.zero_()` sets all elements of a tensor to zero."]},{"cell_type":"markdown","metadata":{},"source":["## Training the linear model"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor(0.4945, grad_fn=<MeanBackward0>)\n"]}],"source":["loss = calc_loss(coeffs,t_indep,t_dep)\n","loss.backward()\n","with torch.no_grad():\n","    coeffs.sub_(coeffs.grad*0.1)\n","    coeffs.grad.zero_()\n","    print(loss)"]},{"cell_type":"markdown","metadata":{},"source":["Before we begin training our model, we'll need to ensure that we hold out a validation set for calculating our metrics (for details on this, see \"[Getting started with NLP for absolute beginners](https://www.kaggle.com/code/jhoward/getting-started-with-nlp-for-absolute-beginners#Test-and-validation-sets)\".\n","\n","There's lots of different ways we can do this. In the next notebook we'll be comparing our approach here to what the fastai library does, so we'll want to ensure we split the data in the same way. So let's use `RandomSplitter` to get indices that will split our data into training and validation sets:"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:35:26.57635Z","iopub.status.busy":"2022-05-30T22:35:26.57605Z","iopub.status.idle":"2022-05-30T22:35:27.821258Z","shell.execute_reply":"2022-05-30T22:35:27.820329Z","shell.execute_reply.started":"2022-05-30T22:35:26.57632Z"},"trusted":true},"outputs":[],"source":["from fastai.data.transforms import RandomSplitter\n","trn_split,val_split=RandomSplitter(seed=42)(df)"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[{"data":{"text/plain":["((#713) [788,525,821,253,374,98,215,313,281,305...],\n"," (#178) [303,778,531,385,134,476,691,443,386,128...])"]},"execution_count":46,"metadata":{},"output_type":"execute_result"}],"source":["from fastai.data.transforms import RandomSplitter\n","trn_split,val_split = RandomSplitter(seed=42)(df)\n","trn_split,val_split"]},{"cell_type":"markdown","metadata":{},"source":["Now we can apply those indicies to our independent and dependent variables:"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:35:27.822887Z","iopub.status.busy":"2022-05-30T22:35:27.822671Z","iopub.status.idle":"2022-05-30T22:35:27.836937Z","shell.execute_reply":"2022-05-30T22:35:27.836081Z","shell.execute_reply.started":"2022-05-30T22:35:27.822859Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(713, 178)"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["trn_indep,val_indep = t_indep[trn_split],t_indep[val_split]\n","trn_dep,val_dep = t_dep[trn_split],t_dep[val_split]\n","len(trn_indep),len(val_indep)"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[{"data":{"text/plain":["(713, 178)"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["trn_indep,val_indep = t_indep[trn_split],t_indep[val_split]\n","trn_dep,val_dep = t_dep[trn_split],t_dep[val_split]\n","len(trn_dep),len(val_dep)"]},{"cell_type":"markdown","metadata":{},"source":["We'll create functions for the three things we did manually above: updating `coeffs`, doing one full gradient descent step, and initilising `coeffs` to random numbers:"]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:35:35.029177Z","iopub.status.busy":"2022-05-30T22:35:35.028649Z","iopub.status.idle":"2022-05-30T22:35:35.034346Z","shell.execute_reply":"2022-05-30T22:35:35.033261Z","shell.execute_reply.started":"2022-05-30T22:35:35.029143Z"},"trusted":true},"outputs":[],"source":["def update_coeffs(coeffs, lr):\n","    coeffs.sub_(coeffs.grad * lr)\n","    coeffs.grad.zero_()"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[],"source":["def update_coeffs(coeffs,lr):\n","    coeffs.sub_(coeffs.grad*lr)\n","    coeffs.grad.zero_()"]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:35:35.633995Z","iopub.status.busy":"2022-05-30T22:35:35.633703Z","iopub.status.idle":"2022-05-30T22:35:35.639103Z","shell.execute_reply":"2022-05-30T22:35:35.63814Z","shell.execute_reply.started":"2022-05-30T22:35:35.633964Z"},"trusted":true},"outputs":[],"source":["def one_epoch(coeffs, lr):\n","    loss = calc_loss(coeffs, trn_indep, trn_dep)\n","    loss.backward()\n","    with torch.no_grad(): update_coeffs(coeffs, lr)\n","    print(f\"{loss:.3f}\", end=\"; \")"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[],"source":["def one_epoch(coeffs,lr):\n","    loss = calc_loss(coeffs,trn_indep,trn_dep)\n","    loss.backward()\n","    with torch.no_grad(): update_coeffs(coeffs,lr)\n","    print(f'{loss:.3f}',end='; ')\n","    '''å†’å·ç”¨äºŽæŒ‡å®šå­—ç¬¦ä¸²æ ¼å¼åŒ–çš„è§„åˆ™'''"]},{"cell_type":"code","execution_count":53,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:35:36.293837Z","iopub.status.busy":"2022-05-30T22:35:36.293565Z","iopub.status.idle":"2022-05-30T22:35:36.297457Z","shell.execute_reply":"2022-05-30T22:35:36.296816Z","shell.execute_reply.started":"2022-05-30T22:35:36.293808Z"},"trusted":true},"outputs":[],"source":["def init_coeffs(): return (torch.rand(n_coeff)-0.5).requires_grad_()"]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[],"source":["def init_coeffs(): return (torch.rand(n_coeff)-0.5).requires_grad_()"]},{"cell_type":"markdown","metadata":{},"source":["We can now use these functions to train our model:"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:35:38.772314Z","iopub.status.busy":"2022-05-30T22:35:38.771827Z","iopub.status.idle":"2022-05-30T22:35:38.777313Z","shell.execute_reply":"2022-05-30T22:35:38.776439Z","shell.execute_reply.started":"2022-05-30T22:35:38.772247Z"},"trusted":true},"outputs":[],"source":["def train_model(epochs=30, lr=0.01):\n","    torch.manual_seed(442)\n","    coeffs = init_coeffs()\n","    for i in range(epochs): one_epoch(coeffs, lr=lr)\n","    return coeffs"]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[],"source":["def train_model(epochs=30,lr= 0.01):\n","    torch.manual_seed(442)\n","    coeffs = init_coeffs()\n","    for i in range(epochs): one_epoch(coeffs,lr)\n","    return coeffs"]},{"cell_type":"markdown","metadata":{},"source":["Let's try it. Our loss will print at the end of every step, so we hope we'll see it going down:"]},{"cell_type":"code","execution_count":57,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:36:14.16788Z","iopub.status.busy":"2022-05-30T22:36:14.16706Z","iopub.status.idle":"2022-05-30T22:36:14.181652Z","shell.execute_reply":"2022-05-30T22:36:14.180496Z","shell.execute_reply.started":"2022-05-30T22:36:14.167812Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0.536; 0.502; 0.477; 0.454; 0.431; 0.409; 0.388; 0.367; 0.349; 0.336; 0.330; 0.326; 0.329; 0.304; 0.314; 0.296; 0.300; 0.289; "]}],"source":["coeffs = train_model(18, lr=0.2)"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.536; 0.502; 0.477; 0.454; 0.431; 0.409; 0.388; 0.367; 0.349; 0.336; 0.330; 0.326; 0.329; 0.304; 0.314; 0.296; 0.300; 0.289; "]},{"data":{"text/plain":["tensor([-0.2694,  0.0901,  0.2359,  0.0280, -0.3990,  0.2345,  0.7232,  0.4112,  0.3601,  0.0955,  0.2395,  0.2122], requires_grad=True)"]},"execution_count":58,"metadata":{},"output_type":"execute_result"}],"source":["coeffs = train_model(18,0.2)\n","coeffs"]},{"cell_type":"markdown","metadata":{},"source":["It does!\n","\n","Let's take a look at the coefficients for each column:"]},{"cell_type":"code","execution_count":59,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:36:21.980389Z","iopub.status.busy":"2022-05-30T22:36:21.97957Z","iopub.status.idle":"2022-05-30T22:36:21.990088Z","shell.execute_reply":"2022-05-30T22:36:21.989021Z","shell.execute_reply.started":"2022-05-30T22:36:21.98035Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'Age': tensor(-0.2694),\n"," 'SibSp': tensor(0.0901),\n"," 'Parch': tensor(0.2359),\n"," 'LogFare': tensor(0.0280),\n"," 'Sex_male': tensor(-0.3990),\n"," 'Sex_female': tensor(0.2345),\n"," 'Pclass_1': tensor(0.7232),\n"," 'Pclass_2': tensor(0.4112),\n"," 'Pclass_3': tensor(0.3601),\n"," 'Embarked_C': tensor(0.0955),\n"," 'Embarked_Q': tensor(0.2395),\n"," 'Embarked_S': tensor(0.2122)}"]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["def show_coeffs(): return dict(zip(indep_cols, coeffs.requires_grad_(False)))\n","show_coeffs()"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[{"data":{"text/plain":["{'Age': tensor(-0.2694),\n"," 'SibSp': tensor(0.0901),\n"," 'Parch': tensor(0.2359),\n"," 'LogFare': tensor(0.0280),\n"," 'Sex_male': tensor(-0.3990),\n"," 'Sex_female': tensor(0.2345),\n"," 'Pclass_1': tensor(0.7232),\n"," 'Pclass_2': tensor(0.4112),\n"," 'Pclass_3': tensor(0.3601),\n"," 'Embarked_C': tensor(0.0955),\n"," 'Embarked_Q': tensor(0.2395),\n"," 'Embarked_S': tensor(0.2122)}"]},"execution_count":60,"metadata":{},"output_type":"execute_result"}],"source":["def show_coeffs(): return dict(zip(indep_cols,coeffs.requires_grad_(False)))\n","show_coeffs()"]},{"cell_type":"markdown","metadata":{},"source":["## Measuring accuracy"]},{"cell_type":"markdown","metadata":{},"source":["The Kaggle competition is not, however, scored by absolute error (which is our loss function). It's scored by *accuracy* -- the proportion of rows where we correctly predict survival. Let's see how accurate we were on the validation set. First, calculate the predictions:"]},{"cell_type":"code","execution_count":61,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:36:30.826372Z","iopub.status.busy":"2022-05-30T22:36:30.825856Z","iopub.status.idle":"2022-05-30T22:36:30.831613Z","shell.execute_reply":"2022-05-30T22:36:30.830756Z","shell.execute_reply.started":"2022-05-30T22:36:30.826322Z"},"trusted":true},"outputs":[],"source":["preds = calc_preds(coeffs, val_indep)"]},{"cell_type":"code","execution_count":62,"metadata":{},"outputs":[],"source":["preds = calc_preds(coeffs,val_indep)"]},{"cell_type":"code","execution_count":63,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([ 0.8160,  0.1295, -0.0148,  0.1831,  0.1520,  0.1350,  0.7279,  0.7754,  0.3222,  0.6740,  0.0753,  0.0389,  0.2216,  0.7631,\n","         0.0678,  0.3997,  0.3324,  0.8278,  0.1078,  0.7126,  0.1023,  0.3627,  0.9937,  0.8050,  0.1153,  0.1455,  0.8652,  0.3425,\n","         0.1262,  0.7630,  0.8877,  0.9052,  0.1191,  0.0804,  0.7958,  0.9393,  0.3941,  0.9915,  0.1023,  0.7437,  0.1713,  0.1023,\n","         0.1949,  0.9650,  0.1158,  0.8820,  0.1039,  0.1551,  0.1290,  0.7422,  0.4583,  0.2953,  0.2823,  0.0984,  0.1477,  0.1275,\n","         0.1295,  0.0759,  0.1124,  0.0900,  0.3338,  0.1366,  0.2824,  0.1124,  0.7358,  0.5246,  0.1554,  0.0564,  0.1290,  0.7183,\n","         0.0955,  0.7004,  0.1309,  0.1030,  0.4703,  0.1291,  0.1023,  0.4399,  0.1722,  0.0785,  0.2994,  1.1087,  0.1056,  0.1019,\n","         0.7005,  0.1302,  0.3914,  1.2342,  0.6726,  0.1587,  0.0755,  0.1023,  0.9732, -0.0350,  0.7629, -0.0018,  0.0842,  0.7901,\n","         0.7697,  0.1458,  0.1730,  0.7630,  0.0753,  0.0821,  0.4615,  0.0948,  0.0828,  0.7903,  0.3671,  0.0962,  0.8402,  0.7269,\n","         0.4710,  1.1176,  0.1023,  0.8819,  0.7904,  0.1295,  0.0415,  0.9489,  0.2204,  0.2879,  0.1295,  0.9293, -0.0148,  0.4541,\n","         0.7324,  0.7290,  0.1299,  0.1022,  1.1361,  0.1165,  0.7627,  0.7603,  1.0061,  0.1192,  0.0377,  0.0862,  0.0249,  0.7539,\n","         0.1352,  0.9090,  0.0311,  0.1025,  0.8138,  0.9887,  0.0555,  0.7021,  1.1720,  0.5902,  0.7819,  0.8417,  0.7981,  0.2733,\n","         0.1566,  0.2803,  0.1023,  0.7614,  0.1217,  0.1047,  0.9900,  0.0363,  0.1174,  0.5266,  0.9558,  1.0885,  0.8397,  0.7283,\n","         0.5145,  0.3667,  0.9276,  0.1216,  1.1260,  0.1030,  0.0349,  1.1465,  0.4711,  0.2062])"]},"execution_count":63,"metadata":{},"output_type":"execute_result"}],"source":["preds"]},{"cell_type":"markdown","metadata":{},"source":["We'll assume that any passenger with a score of over `0.5` is predicted to survive. So that means we're correct for each row where `preds>0.5` is the same as the dependent variable:"]},{"cell_type":"code","execution_count":64,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True, False, False, False,  True,  True, False])"]},"execution_count":64,"metadata":{},"output_type":"execute_result"}],"source":["results = val_dep.bool()==(preds>0.5)\n","results[:16]"]},{"cell_type":"code","execution_count":65,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:36:33.618899Z","iopub.status.busy":"2022-05-30T22:36:33.618455Z","iopub.status.idle":"2022-05-30T22:36:33.62703Z","shell.execute_reply":"2022-05-30T22:36:33.625949Z","shell.execute_reply.started":"2022-05-30T22:36:33.618867Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True, False, False, False,  True,  True, False])"]},"execution_count":65,"metadata":{},"output_type":"execute_result"}],"source":["results = val_dep.bool()==(preds>0.5)\n","results[:16]"]},{"cell_type":"markdown","metadata":{},"source":["Let's see what our average accuracy is:"]},{"cell_type":"code","execution_count":66,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:36:35.725637Z","iopub.status.busy":"2022-05-30T22:36:35.725112Z","iopub.status.idle":"2022-05-30T22:36:35.732969Z","shell.execute_reply":"2022-05-30T22:36:35.732241Z","shell.execute_reply.started":"2022-05-30T22:36:35.725599Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor(0.7865)"]},"execution_count":66,"metadata":{},"output_type":"execute_result"}],"source":["results.float().mean()"]},{"cell_type":"code","execution_count":67,"metadata":{},"outputs":[{"data":{"text/plain":["tensor(0.7865)"]},"execution_count":67,"metadata":{},"output_type":"execute_result"}],"source":["results.float().mean()"]},{"cell_type":"markdown","metadata":{},"source":["That's not a bad start at all! We'll create a function so we can calcuate the accuracy easy for other models we train:"]},{"cell_type":"code","execution_count":68,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:36:40.356505Z","iopub.status.busy":"2022-05-30T22:36:40.356043Z","iopub.status.idle":"2022-05-30T22:36:40.365187Z","shell.execute_reply":"2022-05-30T22:36:40.364153Z","shell.execute_reply.started":"2022-05-30T22:36:40.356471Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor(0.7865)"]},"execution_count":68,"metadata":{},"output_type":"execute_result"}],"source":["def acc(coeffs): return (val_dep.bool()==(calc_preds(coeffs, val_indep)>0.5)).float().mean()\n","acc(coeffs)"]},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[{"data":{"text/plain":["tensor(0.7865)"]},"execution_count":69,"metadata":{},"output_type":"execute_result"}],"source":["def acc(coeffs): return (val_dep.bool()==(calc_preds(coeffs,val_indep)>0.5)).float().mean()\n","acc(coeffs)"]},{"cell_type":"markdown","metadata":{},"source":["## Using sigmoid"]},{"cell_type":"markdown","metadata":{},"source":["Looking at our predictions, there's one obvious problem -- some of our predictions of the probability of survival are `>1`, and some are `<0`:"]},{"cell_type":"code","execution_count":70,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:36:42.344823Z","iopub.status.busy":"2022-05-30T22:36:42.344533Z","iopub.status.idle":"2022-05-30T22:36:42.352948Z","shell.execute_reply":"2022-05-30T22:36:42.351968Z","shell.execute_reply.started":"2022-05-30T22:36:42.344794Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([ 0.8160,  0.1295, -0.0148,  0.1831,  0.1520,  0.1350,  0.7279,  0.7754,  0.3222,  0.6740,  0.0753,  0.0389,  0.2216,  0.7631,\n","         0.0678,  0.3997,  0.3324,  0.8278,  0.1078,  0.7126,  0.1023,  0.3627,  0.9937,  0.8050,  0.1153,  0.1455,  0.8652,  0.3425])"]},"execution_count":70,"metadata":{},"output_type":"execute_result"}],"source":["preds[:28]"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[{"data":{"text/plain":["tensor(1.2342)"]},"execution_count":71,"metadata":{},"output_type":"execute_result"}],"source":["preds.max()"]},{"cell_type":"markdown","metadata":{},"source":["To fix this, we should pass every prediction through the *sigmoid function*, which has a minimum at zero and maximum at one, and is defined as follows:"]},{"cell_type":"code","execution_count":72,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:36:44.914015Z","iopub.status.busy":"2022-05-30T22:36:44.913101Z","iopub.status.idle":"2022-05-30T22:36:46.311818Z","shell.execute_reply":"2022-05-30T22:36:46.311008Z","shell.execute_reply.started":"2022-05-30T22:36:44.913968Z"},"trusted":true},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import sympy\n","sympy.plot(\"1/(1+exp(-x))\", xlim=(-5,5));"]},{"cell_type":"code","execution_count":73,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["<sympy.plotting.plot.Plot at 0x25e2c0095e0>"]},"execution_count":73,"metadata":{},"output_type":"execute_result"}],"source":["import sympy\n","sympy.plot('1/(1+exp(-x))',xlim=(-5,5))"]},{"cell_type":"markdown","metadata":{},"source":["PyTorch already defines that function for us, so we can modify `calc_preds` to use it:"]},{"cell_type":"code","execution_count":74,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:36:46.313644Z","iopub.status.busy":"2022-05-30T22:36:46.313435Z","iopub.status.idle":"2022-05-30T22:36:46.317749Z","shell.execute_reply":"2022-05-30T22:36:46.3169Z","shell.execute_reply.started":"2022-05-30T22:36:46.313618Z"},"trusted":true},"outputs":[],"source":["def calc_preds(coeffs, indeps): return torch.sigmoid((indeps*coeffs).sum(axis=1))"]},{"cell_type":"code","execution_count":75,"metadata":{},"outputs":[],"source":["def calc_preds(coeffs,indeps): return torch.sigmoid((indeps*coeffs).sum(axis=1))"]},{"cell_type":"markdown","metadata":{},"source":["Let's train a new model now, using this updated function to calculate predictions:"]},{"cell_type":"code","execution_count":76,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:38:23.22576Z","iopub.status.busy":"2022-05-30T22:38:23.225051Z","iopub.status.idle":"2022-05-30T22:38:23.250206Z","shell.execute_reply":"2022-05-30T22:38:23.249321Z","shell.execute_reply.started":"2022-05-30T22:38:23.225722Z"},"trusted":true},"outputs":[],"source":["# coeffs = train_model(lr=100)"]},{"cell_type":"code","execution_count":77,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.510; 0.327; 0.294; 0.207; 0.201; 0.199; 0.198; 0.197; 0.196; 0.196; 0.196; 0.195; 0.195; 0.195; 0.195; 0.195; 0.195; 0.195; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; 0.194; "]}],"source":["coeffs = train_model(lr=100)"]},{"cell_type":"markdown","metadata":{},"source":["The loss has improved by a lot. Let's check the accuracy:"]},{"cell_type":"code","execution_count":78,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:38:28.519132Z","iopub.status.busy":"2022-05-30T22:38:28.518642Z","iopub.status.idle":"2022-05-30T22:38:28.527145Z","shell.execute_reply":"2022-05-30T22:38:28.526248Z","shell.execute_reply.started":"2022-05-30T22:38:28.519078Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor(0.8258)"]},"execution_count":78,"metadata":{},"output_type":"execute_result"}],"source":["acc(coeffs)"]},{"cell_type":"code","execution_count":79,"metadata":{},"outputs":[{"data":{"text/plain":["tensor(0.8258)"]},"execution_count":79,"metadata":{},"output_type":"execute_result"}],"source":["acc(coeffs)"]},{"cell_type":"markdown","metadata":{},"source":["That's improved too! Here's the coefficients of our trained model:"]},{"cell_type":"code","execution_count":80,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:38:32.01697Z","iopub.status.busy":"2022-05-30T22:38:32.015953Z","iopub.status.idle":"2022-05-30T22:38:32.02724Z","shell.execute_reply":"2022-05-30T22:38:32.026125Z","shell.execute_reply.started":"2022-05-30T22:38:32.016924Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'Age': tensor(-1.5061),\n"," 'SibSp': tensor(-1.1575),\n"," 'Parch': tensor(-0.4267),\n"," 'LogFare': tensor(0.2543),\n"," 'Sex_male': tensor(-10.3320),\n"," 'Sex_female': tensor(8.4185),\n"," 'Pclass_1': tensor(3.8389),\n"," 'Pclass_2': tensor(2.1398),\n"," 'Pclass_3': tensor(-6.2331),\n"," 'Embarked_C': tensor(1.4771),\n"," 'Embarked_Q': tensor(2.1168),\n"," 'Embarked_S': tensor(-4.7958)}"]},"execution_count":80,"metadata":{},"output_type":"execute_result"}],"source":["show_coeffs()"]},{"cell_type":"code","execution_count":81,"metadata":{},"outputs":[{"data":{"text/plain":["{'Age': tensor(-1.5061),\n"," 'SibSp': tensor(-1.1575),\n"," 'Parch': tensor(-0.4267),\n"," 'LogFare': tensor(0.2543),\n"," 'Sex_male': tensor(-10.3320),\n"," 'Sex_female': tensor(8.4185),\n"," 'Pclass_1': tensor(3.8389),\n"," 'Pclass_2': tensor(2.1398),\n"," 'Pclass_3': tensor(-6.2331),\n"," 'Embarked_C': tensor(1.4771),\n"," 'Embarked_Q': tensor(2.1168),\n"," 'Embarked_S': tensor(-4.7958)}"]},"execution_count":81,"metadata":{},"output_type":"execute_result"}],"source":["show_coeffs()"]},{"cell_type":"markdown","metadata":{},"source":["These coefficients seem reasonable -- in general, older people and males were less likely to survive, and first class passengers were more likely to survive."]},{"cell_type":"markdown","metadata":{},"source":["## Submitting to Kaggle"]},{"cell_type":"markdown","metadata":{},"source":["Now that we've got a trained model, we can prepare a submission to Kaggle. To do that, first we need to read the test set:"]},{"cell_type":"code","execution_count":82,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:38:35.172909Z","iopub.status.busy":"2022-05-30T22:38:35.172343Z","iopub.status.idle":"2022-05-30T22:38:35.188597Z","shell.execute_reply":"2022-05-30T22:38:35.187826Z","shell.execute_reply.started":"2022-05-30T22:38:35.172873Z"},"trusted":true},"outputs":[],"source":["tst_df = pd.read_csv(path/'test.csv')"]},{"cell_type":"code","execution_count":83,"metadata":{},"outputs":[],"source":["tst_df = pd.read_csv(path/'test.csv')"]},{"cell_type":"code","execution_count":84,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Pclass</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Fare</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>418.000000</td>\n","      <td>418.000000</td>\n","      <td>332.000000</td>\n","      <td>418.000000</td>\n","      <td>418.000000</td>\n","      <td>417.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>1100.500000</td>\n","      <td>2.265550</td>\n","      <td>30.272590</td>\n","      <td>0.447368</td>\n","      <td>0.392344</td>\n","      <td>35.627188</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>120.810458</td>\n","      <td>0.841838</td>\n","      <td>14.181209</td>\n","      <td>0.896760</td>\n","      <td>0.981429</td>\n","      <td>55.907576</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>892.000000</td>\n","      <td>1.000000</td>\n","      <td>0.170000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>996.250000</td>\n","      <td>1.000000</td>\n","      <td>21.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>7.895800</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>1100.500000</td>\n","      <td>3.000000</td>\n","      <td>27.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>14.454200</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>1204.750000</td>\n","      <td>3.000000</td>\n","      <td>39.000000</td>\n","      <td>1.000000</td>\n","      <td>0.000000</td>\n","      <td>31.500000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>1309.000000</td>\n","      <td>3.000000</td>\n","      <td>76.000000</td>\n","      <td>8.000000</td>\n","      <td>9.000000</td>\n","      <td>512.329200</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       PassengerId      Pclass         Age       SibSp       Parch        Fare\n","count   418.000000  418.000000  332.000000  418.000000  418.000000  417.000000\n","mean   1100.500000    2.265550   30.272590    0.447368    0.392344   35.627188\n","std     120.810458    0.841838   14.181209    0.896760    0.981429   55.907576\n","min     892.000000    1.000000    0.170000    0.000000    0.000000    0.000000\n","25%     996.250000    1.000000   21.000000    0.000000    0.000000    7.895800\n","50%    1100.500000    3.000000   27.000000    0.000000    0.000000   14.454200\n","75%    1204.750000    3.000000   39.000000    1.000000    0.000000   31.500000\n","max    1309.000000    3.000000   76.000000    8.000000    9.000000  512.329200"]},"execution_count":84,"metadata":{},"output_type":"execute_result"}],"source":["tst_df.describe()"]},{"cell_type":"code","execution_count":85,"metadata":{},"outputs":[{"data":{"text/plain":["PassengerId      0\n","Pclass           0\n","Name             0\n","Sex              0\n","Age             86\n","SibSp            0\n","Parch            0\n","Ticket           0\n","Fare             1\n","Cabin          327\n","Embarked         0\n","dtype: int64"]},"execution_count":85,"metadata":{},"output_type":"execute_result"}],"source":["tst_df.isna().sum()"]},{"cell_type":"markdown","metadata":{},"source":["In this case, it turns out that the test set is missing `Fare` for one passenger. We'll just fill it with `0` to avoid problems:"]},{"cell_type":"code","execution_count":86,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:38:36.353392Z","iopub.status.busy":"2022-05-30T22:38:36.352687Z","iopub.status.idle":"2022-05-30T22:38:36.358237Z","shell.execute_reply":"2022-05-30T22:38:36.35739Z","shell.execute_reply.started":"2022-05-30T22:38:36.353355Z"},"trusted":true},"outputs":[],"source":["tst_df['Fare'] = tst_df.Fare.fillna(0)"]},{"cell_type":"code","execution_count":87,"metadata":{},"outputs":[],"source":["tst_df['Fare'] = tst_df.Fare.fillna(0)"]},{"cell_type":"markdown","metadata":{},"source":["Now we can just copy the same steps we did to our training set and do the same exact things on our test set to preprocess the data:"]},{"cell_type":"code","execution_count":88,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:38:38.198549Z","iopub.status.busy":"2022-05-30T22:38:38.198257Z","iopub.status.idle":"2022-05-30T22:38:38.220592Z","shell.execute_reply":"2022-05-30T22:38:38.219629Z","shell.execute_reply.started":"2022-05-30T22:38:38.198519Z"},"trusted":true},"outputs":[],"source":["# tst_df.fillna(modes, inplace=True)\n","# tst_df['LogFare'] = np.log(tst_df['Fare']+1)\n","# tst_df = pd.get_dummies(tst_df, columns=[\"Sex\",\"Pclass\",\"Embarked\"])\n","\n","# tst_indep = tensor(tst_df[indep_cols].values, dtype=torch.float)\n","# tst_indep = tst_indep / vals"]},{"cell_type":"code","execution_count":89,"metadata":{},"outputs":[],"source":["tst_df.fillna(modes,inplace=True)\n","tst_df['LogFare'] = np.log(tst_df['Fare']+1)\n","tst_df = pd.get_dummies(tst_df,columns=[\"Sex\",\"Pclass\",\"Embarked\"])\n"]},{"cell_type":"code","execution_count":90,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sex_male</th>\n","      <th>Sex_female</th>\n","      <th>Pclass_1</th>\n","      <th>Pclass_2</th>\n","      <th>Pclass_3</th>\n","      <th>Embarked_C</th>\n","      <th>Embarked_Q</th>\n","      <th>Embarked_S</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>413</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>414</th>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","    <tr>\n","      <th>415</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>416</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>417</th>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>False</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>418 rows Ã— 8 columns</p>\n","</div>"],"text/plain":["     Sex_male  Sex_female  Pclass_1  Pclass_2  Pclass_3  Embarked_C  Embarked_Q  Embarked_S\n","0        True       False     False     False      True       False        True       False\n","1       False        True     False     False      True       False       False        True\n","2        True       False     False      True     False       False        True       False\n","3        True       False     False     False      True       False       False        True\n","4       False        True     False     False      True       False       False        True\n","..        ...         ...       ...       ...       ...         ...         ...         ...\n","413      True       False     False     False      True       False       False        True\n","414     False        True      True     False     False        True       False       False\n","415      True       False     False     False      True       False       False        True\n","416      True       False     False     False      True       False       False        True\n","417      True       False     False     False      True        True       False       False\n","\n","[418 rows x 8 columns]"]},"execution_count":90,"metadata":{},"output_type":"execute_result"}],"source":["tst_df[added_cols]"]},{"cell_type":"code","execution_count":91,"metadata":{},"outputs":[],"source":["tst_df[added_cols] = tst_df[added_cols].astype(float)\n","tst_indep = tensor(tst_df[indep_cols].values,dtype=torch.float)\n","tst_indep = tst_indep/vals"]},{"cell_type":"markdown","metadata":{},"source":["Let's calculate our predictions of which passengers survived in the test set:"]},{"cell_type":"code","execution_count":92,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:38:39.206547Z","iopub.status.busy":"2022-05-30T22:38:39.206216Z","iopub.status.idle":"2022-05-30T22:38:39.212386Z","shell.execute_reply":"2022-05-30T22:38:39.211631Z","shell.execute_reply.started":"2022-05-30T22:38:39.206512Z"},"trusted":true},"outputs":[],"source":["tst_df['Survived'] = (calc_preds(tst_indep, coeffs)>0.5).int()"]},{"cell_type":"code","execution_count":93,"metadata":{},"outputs":[{"data":{"text/plain":["111"]},"execution_count":93,"metadata":{},"output_type":"execute_result"}],"source":["\n","tst_df['Survived'].sum()"]},{"cell_type":"code","execution_count":94,"metadata":{},"outputs":[],"source":["tst_df['Survived'] = (calc_preds(coeffs,tst_indep)>0.5).int()"]},{"cell_type":"markdown","metadata":{},"source":["The sample submission on the Kaggle competition site shows that we're expected to upload a CSV with just `PassengerId` and `Survived`, so let's create that and save it:"]},{"cell_type":"code","execution_count":95,"metadata":{},"outputs":[{"data":{"text/plain":["Index(['PassengerId', 'Name', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'LogFare', 'Sex_female', 'Sex_male', 'Pclass_1',\n","       'Pclass_2', 'Pclass_3', 'Embarked_C', 'Embarked_Q', 'Embarked_S', 'Survived'],\n","      dtype='object')"]},"execution_count":95,"metadata":{},"output_type":"execute_result"}],"source":["tst_df.columns"]},{"cell_type":"code","execution_count":96,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:38:40.161382Z","iopub.status.busy":"2022-05-30T22:38:40.161034Z","iopub.status.idle":"2022-05-30T22:38:40.173242Z","shell.execute_reply":"2022-05-30T22:38:40.17258Z","shell.execute_reply.started":"2022-05-30T22:38:40.161336Z"},"trusted":true},"outputs":[],"source":["sub_df = tst_df[['PassengerId','Survived']]\n","sub_df.to_csv('sub.csv', index=False)"]},{"cell_type":"code","execution_count":97,"metadata":{},"outputs":[],"source":["sub_df = tst_df[['PassengerId','Survived']]\n","sub_df.to_csv('sub.csv',index=False)"]},{"cell_type":"markdown","metadata":{},"source":["We can check the first few rows of the file to make sure it looks reasonable:"]},{"cell_type":"code","execution_count":98,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:38:42.869402Z","iopub.status.busy":"2022-05-30T22:38:42.86855Z","iopub.status.idle":"2022-05-30T22:38:43.638832Z","shell.execute_reply":"2022-05-30T22:38:43.637559Z","shell.execute_reply.started":"2022-05-30T22:38:42.869362Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["'head' ï¿½ï¿½ï¿½ï¿½ï¿½Ú²ï¿½ï¿½ï¿½ï¿½â²¿ï¿½ï¿½ï¿½î£¬Ò²ï¿½ï¿½ï¿½Ç¿ï¿½ï¿½ï¿½ï¿½ÐµÄ³ï¿½ï¿½ï¿½\n","ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ä¼ï¿½ï¿½ï¿½\n"]}],"source":["!head sub.csv"]},{"cell_type":"code","execution_count":99,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["'head' ï¿½ï¿½ï¿½ï¿½ï¿½Ú²ï¿½ï¿½ï¿½ï¿½â²¿ï¿½ï¿½ï¿½î£¬Ò²ï¿½ï¿½ï¿½Ç¿ï¿½ï¿½ï¿½ï¿½ÐµÄ³ï¿½ï¿½ï¿½\n","ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½Ä¼ï¿½ï¿½ï¿½\n"]}],"source":["!head -e UTF-8 sub.csv"]},{"cell_type":"markdown","metadata":{},"source":["When you click \"save version\" in Kaggle, and wait for the notebook to run, you'll see that `sub.csv` appears in the \"Data\" tab. Clicking on that file will show a *Submit* button, which allows you to submit to the competition."]},{"cell_type":"markdown","metadata":{},"source":["## Using matrix product"]},{"cell_type":"markdown","metadata":{},"source":["We can make things quite a bit neater...\n","\n","Take a look at the inner-most calculation we're doing to get the predictions:"]},{"cell_type":"code","execution_count":100,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:38:48.248084Z","iopub.status.busy":"2022-05-30T22:38:48.247768Z","iopub.status.idle":"2022-05-30T22:38:48.258935Z","shell.execute_reply":"2022-05-30T22:38:48.258184Z","shell.execute_reply.started":"2022-05-30T22:38:48.248052Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([ 12.3288, -14.8119, -15.4540, -13.1513, -13.3511, -13.6468,   3.6248,   5.3429, -22.0878,   3.1233, -21.8742, -15.6421, -21.5504,\n","          3.9393, -21.9190, -12.0010, -12.3775,   5.3550, -13.5880,  -3.1015, -21.7237, -12.2081,  12.9767,   4.7427, -21.6525, -14.9135,\n","         -2.7433, -12.3210, -21.5886,   3.9387,   5.3890,  -3.6196, -21.6296, -21.8454,  12.2159,  -3.2275, -12.0289,  13.4560, -21.7230,\n","         -3.1366, -13.2462, -21.7230, -13.6831,  13.3092, -21.6477,  -3.5868, -21.6854, -21.8316, -14.8158,  -2.9386,  -5.3103, -22.2384,\n","        -22.1097, -21.7466, -13.3780, -13.4909, -14.8119, -22.0690, -21.6666, -21.7818,  -5.4439, -21.7407, -12.6551, -21.6671,   4.9238,\n","        -11.5777, -13.3323, -21.9638, -15.3030,   5.0243, -21.7614,   3.1820, -13.4721, -21.7170, -11.6066, -21.5737, -21.7230, -11.9652,\n","        -13.2382, -13.7599, -13.2170,  13.1347, -21.7049, -21.7268,   4.9207,  -7.3198,  -5.3081,   7.1066,  11.4948, -13.3135, -21.8723,\n","        -21.7230,  13.3603, -15.5669,   3.4105,  -7.2857, -13.7197,   3.6909,   3.9763, -14.7227, -21.8268,   3.9387, -21.8743, -21.8367,\n","        -11.8518, -13.6712, -21.8299,   4.9440,  -5.4471, -21.9666,   5.1333,  -3.2187, -11.6008,  13.7920, -21.7230,  12.6369,  -3.7268,\n","        -14.8119, -22.0637,  12.9468, -22.1610,  -6.1827, -14.8119,  -3.2838, -15.4540, -11.6950,  -2.9926,  -3.0110, -21.5664, -13.8268,\n","          7.3426, -21.8418,   5.0744,   5.2582,  13.3415, -21.6289, -13.9898, -21.8112,  -7.3316,   5.2296, -13.4453,  12.7891, -22.1235,\n","        -14.9625,  -3.4339,   6.3089, -21.9839,   3.1968,   7.2400,   2.8558,  -3.1187,   3.7965,   5.4667, -15.1101, -15.0597, -22.9391,\n","        -21.7230,  -3.0346, -13.5206, -21.7011,  13.4425,  -7.2690, -21.8335, -12.0582,  13.0489,   6.7993,   5.2160,   5.0794, -12.6957,\n","        -12.1838,  -3.0873, -21.6070,   7.0745, -21.7170, -22.1001,   6.8159, -11.6002, -21.6310])"]},"execution_count":100,"metadata":{},"output_type":"execute_result"}],"source":["(val_indep*coeffs).sum(axis=1)"]},{"cell_type":"markdown","metadata":{},"source":["Multiplying elements together and then adding across rows is identical to doing a matrix-vector product! Python uses the `@` operator to indicate matrix products, and is supported by PyTorch tensors. Therefore, we can replicate the above calculate more simply like so:"]},{"cell_type":"code","execution_count":101,"metadata":{},"outputs":[{"data":{"text/plain":["'\\nå¦‚æžœnn.reshape(1,4),åˆ™æŠ¥é”™mat1 and mat2 shapes cannot be multiplied (3x4 and 1x4)\\nç›®å‰mm,nnçš„shapeåˆ†åˆ«æ˜¯(torch.Size([3, 4]), torch.Size([4]))\\nåˆ™ä¼šåœ¨nnç¬¬äºŒä¸ªç»´åº¦ä¸Šè¡¥ä¸€ä¸ªç»´åº¦ï¼Œä½¿å¾—å®ƒä»¬åšçŸ©é˜µä¹˜æ³•\\nå¦‚æžœæ˜¯nn@mmï¼Œåˆ™ä¼šæŠ¥é”™mat1 and mat2 shapes cannot be multiplied (1x4 and 3x4)\\nåˆ™ä¼šåœ¨å·¦ä¾§çš„å‰é¢åŠ ä¸€ä¸ªç»´åº¦ï¼Œä¹Ÿå°±æ˜¯è¡¥ç¬¬ä¸€ä¸ªç»´åº¦ã€‚\\næ€»ä¹‹ï¼Œç»´åº¦ä¸å¤Ÿçš„ï¼Œåœ¨å·¦è¾¹çš„å·¦ä¾§è¡¥ï¼Œåœ¨å³è¾¹çš„å³ä¾§è¡¥\\n'"]},"execution_count":101,"metadata":{},"output_type":"execute_result"}],"source":["mm = torch.arange(12).reshape(3,4)\n","nn = torch.tensor([1,2,3,4])\n","mm,nn,mm@nn\n","'''\n","å¦‚æžœnn.reshape(1,4),åˆ™æŠ¥é”™mat1 and mat2 shapes cannot be multiplied (3x4 and 1x4)\n","ç›®å‰mm,nnçš„shapeåˆ†åˆ«æ˜¯(torch.Size([3, 4]), torch.Size([4]))\n","åˆ™ä¼šåœ¨nnç¬¬äºŒä¸ªç»´åº¦ä¸Šè¡¥ä¸€ä¸ªç»´åº¦ï¼Œä½¿å¾—å®ƒä»¬åšçŸ©é˜µä¹˜æ³•\n","å¦‚æžœæ˜¯nn@mmï¼Œåˆ™ä¼šæŠ¥é”™mat1 and mat2 shapes cannot be multiplied (1x4 and 3x4)\n","åˆ™ä¼šåœ¨å·¦ä¾§çš„å‰é¢åŠ ä¸€ä¸ªç»´åº¦ï¼Œä¹Ÿå°±æ˜¯è¡¥ç¬¬ä¸€ä¸ªç»´åº¦ã€‚\n","æ€»ä¹‹ï¼Œç»´åº¦ä¸å¤Ÿçš„ï¼Œåœ¨å·¦è¾¹çš„å·¦ä¾§è¡¥ï¼Œåœ¨å³è¾¹çš„å³ä¾§è¡¥\n","'''"]},{"cell_type":"code","execution_count":102,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:38:51.959798Z","iopub.status.busy":"2022-05-30T22:38:51.959362Z","iopub.status.idle":"2022-05-30T22:38:51.97614Z","shell.execute_reply":"2022-05-30T22:38:51.975461Z","shell.execute_reply.started":"2022-05-30T22:38:51.959765Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([ 12.3288, -14.8119, -15.4540, -13.1513, -13.3511, -13.6468,   3.6248,   5.3429, -22.0878,   3.1233, -21.8742, -15.6421, -21.5504,\n","          3.9393, -21.9190, -12.0010, -12.3775,   5.3550, -13.5880,  -3.1015, -21.7237, -12.2081,  12.9767,   4.7427, -21.6525, -14.9135,\n","         -2.7433, -12.3210, -21.5886,   3.9387,   5.3890,  -3.6196, -21.6296, -21.8454,  12.2159,  -3.2275, -12.0289,  13.4560, -21.7230,\n","         -3.1366, -13.2462, -21.7230, -13.6831,  13.3092, -21.6477,  -3.5868, -21.6854, -21.8316, -14.8158,  -2.9386,  -5.3103, -22.2384,\n","        -22.1097, -21.7466, -13.3780, -13.4909, -14.8119, -22.0690, -21.6666, -21.7818,  -5.4439, -21.7407, -12.6551, -21.6671,   4.9238,\n","        -11.5777, -13.3323, -21.9638, -15.3030,   5.0243, -21.7614,   3.1820, -13.4721, -21.7170, -11.6066, -21.5737, -21.7230, -11.9652,\n","        -13.2382, -13.7599, -13.2170,  13.1347, -21.7049, -21.7268,   4.9207,  -7.3198,  -5.3081,   7.1065,  11.4948, -13.3135, -21.8723,\n","        -21.7230,  13.3603, -15.5670,   3.4105,  -7.2857, -13.7197,   3.6909,   3.9763, -14.7227, -21.8268,   3.9387, -21.8743, -21.8367,\n","        -11.8518, -13.6712, -21.8299,   4.9440,  -5.4471, -21.9666,   5.1333,  -3.2187, -11.6008,  13.7920, -21.7230,  12.6369,  -3.7268,\n","        -14.8119, -22.0637,  12.9468, -22.1610,  -6.1827, -14.8119,  -3.2838, -15.4540, -11.6950,  -2.9926,  -3.0110, -21.5664, -13.8268,\n","          7.3426, -21.8418,   5.0744,   5.2582,  13.3415, -21.6289, -13.9898, -21.8112,  -7.3316,   5.2296, -13.4453,  12.7891, -22.1235,\n","        -14.9625,  -3.4339,   6.3089, -21.9839,   3.1968,   7.2400,   2.8558,  -3.1187,   3.7965,   5.4667, -15.1101, -15.0597, -22.9391,\n","        -21.7230,  -3.0346, -13.5206, -21.7011,  13.4425,  -7.2690, -21.8335, -12.0582,  13.0489,   6.7993,   5.2160,   5.0794, -12.6957,\n","        -12.1838,  -3.0873, -21.6070,   7.0745, -21.7170, -22.1001,   6.8159, -11.6002, -21.6310])"]},"execution_count":102,"metadata":{},"output_type":"execute_result"}],"source":["val_indep@coeffs"]},{"cell_type":"markdown","metadata":{},"source":["It also turns out that this is much faster, because matrix products in PyTorch are very highly optimised.\n","\n","Let's use this to replace how `calc_preds` works:"]},{"cell_type":"code","execution_count":103,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:38:56.322255Z","iopub.status.busy":"2022-05-30T22:38:56.321807Z","iopub.status.idle":"2022-05-30T22:38:56.326812Z","shell.execute_reply":"2022-05-30T22:38:56.32606Z","shell.execute_reply.started":"2022-05-30T22:38:56.322213Z"},"trusted":true},"outputs":[],"source":["def calc_preds(coeffs, indeps): return torch.sigmoid(indeps@coeffs)"]},{"cell_type":"code","execution_count":104,"metadata":{},"outputs":[],"source":["def calc_preds(coeffs,indeps): return torch.sigmoid(indeps@coeffs)"]},{"cell_type":"markdown","metadata":{},"source":["In order to do matrix-matrix products (which we'll need in the next section), we need to turn `coeffs` into a column vector (i.e. a matrix with a single column), which we can do by passing a second argument `1` to `torch.rand()`, indicating that we want our coefficients to have one column:"]},{"cell_type":"code","execution_count":105,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:38:58.895779Z","iopub.status.busy":"2022-05-30T22:38:58.895467Z","iopub.status.idle":"2022-05-30T22:38:58.900851Z","shell.execute_reply":"2022-05-30T22:38:58.899931Z","shell.execute_reply.started":"2022-05-30T22:38:58.895744Z"},"trusted":true},"outputs":[],"source":["def init_coeffs(): return (torch.rand(n_coeff, 1)*0.1).requires_grad_()"]},{"cell_type":"code","execution_count":106,"metadata":{},"outputs":[],"source":["def init_coeffs(): return (torch.rand(n_coeff,1)*0.1).requires_grad_()"]},{"cell_type":"markdown","metadata":{},"source":["We'll also need to turn our dependent variable into a column vector, which we can do by indexing the column dimension with the special value `None`, which tells PyTorch to add a new dimension in this position:"]},{"cell_type":"code","execution_count":107,"metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([713, 1])"]},"execution_count":107,"metadata":{},"output_type":"execute_result"}],"source":["trn_dep = trn_dep.reshape([713, 1])\n","trn_dep.shape"]},{"cell_type":"code","execution_count":108,"metadata":{},"outputs":[],"source":["trn_dep = trn_dep[:,None]\n","val_dep = val_dep[:,None]\n","'''æœ«å°¾åŠ ä¸€ä¸ªç»´åº¦'''"]},{"cell_type":"markdown","metadata":{},"source":["We can now train our model as before and confirm we get identical outputs...:"]},{"cell_type":"code","execution_count":109,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.512; 0.379; 0.379; 0.379; 0.379; 0.379; 0.379; 0.379; 0.379; 0.379; 0.379; 0.379; 0.379; 0.379; 0.379; 0.379; 0.379; 0.379; 0.379; 0.379; 0.379; 0.379; 0.379; 0.379; 0.379; 0.379; 0.379; 0.379; 0.379; 0.379; "]}],"source":["coeffs = train_model(lr=100)"]},{"cell_type":"markdown","metadata":{},"source":["...and identical accuracy:"]},{"cell_type":"code","execution_count":110,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:39:40.463735Z","iopub.status.busy":"2022-05-30T22:39:40.463301Z","iopub.status.idle":"2022-05-30T22:39:40.469684Z","shell.execute_reply":"2022-05-30T22:39:40.468652Z","shell.execute_reply.started":"2022-05-30T22:39:40.463702Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor(0.5955)"]},"execution_count":110,"metadata":{},"output_type":"execute_result"}],"source":["acc(coeffs)"]},{"cell_type":"code","execution_count":111,"metadata":{},"outputs":[{"data":{"text/plain":["tensor(0.5955)"]},"execution_count":111,"metadata":{},"output_type":"execute_result"}],"source":["acc(coeffs)"]},{"cell_type":"markdown","metadata":{},"source":["## A neural network"]},{"cell_type":"markdown","metadata":{},"source":["We've now got what we need to implement our neural network.\n","\n","First, we'll need to create coefficients for each of our layers. Our first set of coefficients will take our `n_coeff` inputs, and create `n_hidden` outputs. We can choose whatever `n_hidden` we like -- a higher number gives our network more flexibility, but makes it slower and harder to train. So we need a matrix of size `n_coeff` by `n_hidden`. We'll divide these coefficients by `n_hidden` so that when we sum them up in the next layer we'll end up with similar magnitude numbers to what we started with.\n","\n","Then our second layer will need to take the `n_hidden` inputs and create a single output, so that means we need a `n_hidden` by `1` matrix there. The second layer will also need a constant term added."]},{"cell_type":"code","execution_count":112,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[0.6722, 0.7324, 0.1425, 0.4990],\n","        [0.3167, 0.2589, 0.5489, 0.5866],\n","        [0.4466, 0.8132, 0.3513, 0.2449]])"]},"execution_count":112,"metadata":{},"output_type":"execute_result"}],"source":["torch.rand(3,4)"]},{"cell_type":"code","execution_count":113,"metadata":{},"outputs":[{"data":{"text/plain":["tensor(0.8328)"]},"execution_count":113,"metadata":{},"output_type":"execute_result"}],"source":["const = torch.rand(1)[0]\n","const"]},{"cell_type":"code","execution_count":114,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:39:44.428599Z","iopub.status.busy":"2022-05-30T22:39:44.428254Z","iopub.status.idle":"2022-05-30T22:39:44.434009Z","shell.execute_reply":"2022-05-30T22:39:44.433164Z","shell.execute_reply.started":"2022-05-30T22:39:44.428563Z"},"trusted":true},"outputs":[],"source":["def init_coeffs(n_hidden=20):\n","    layer1 = (torch.rand(n_coeff, n_hidden)-0.5)/n_hidden\n","    layer2 = torch.rand(n_hidden, 1)-0.3\n","    const = torch.rand(1)[0]\n","    return layer1.requires_grad_(),layer2.requires_grad_(),const.requires_grad_()"]},{"cell_type":"code","execution_count":115,"metadata":{},"outputs":[],"source":["def init_coeffs(n_hidden = 20):\n","    layer1 = (torch.rand(n_coeff,n_hidden)-0.5)/n_hidden\n","    layer2 = torch.rand(n_hidden,1)-0.3\n","    const = torch.rand(1)[0]\n","    return layer1.requires_grad_(),layer2.requires_grad_(),const.requires_grad_()"]},{"cell_type":"markdown","metadata":{},"source":["Now we have our coefficients, we can create our neural net. The key steps are the two matrix products, `indeps@l1` and `res@l2` (where `res` is the output of the first layer). The first layer output is passed to `F.relu` (that's our non-linearity), and the second is passed to `torch.sigmoid` as before."]},{"cell_type":"code","execution_count":116,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:39:45.302903Z","iopub.status.busy":"2022-05-30T22:39:45.302573Z","iopub.status.idle":"2022-05-30T22:39:45.309472Z","shell.execute_reply":"2022-05-30T22:39:45.308498Z","shell.execute_reply.started":"2022-05-30T22:39:45.302864Z"},"trusted":true},"outputs":[],"source":["import torch.nn.functional as F\n","\n","def calc_preds(coeffs, indeps):\n","    l1,l2,const = coeffs\n","    res = F.relu(indeps@l1)\n","    res = res@l2 + const\n","    return torch.sigmoid(res)"]},{"cell_type":"code","execution_count":117,"metadata":{},"outputs":[],"source":["import torch.nn.functional as F\n","def calc_preds(coeffs,indeps):\n","    l1,l2,const = coeffs\n","    res = F.relu(indeps@l1)\n","    res = res@l2+const\n","    return torch.sigmoid(res)"]},{"cell_type":"markdown","metadata":{},"source":["Finally, now that we have more than one set of coefficients, we need to add a loop to update each one:"]},{"cell_type":"code","execution_count":118,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:39:55.366945Z","iopub.status.busy":"2022-05-30T22:39:55.3665Z","iopub.status.idle":"2022-05-30T22:39:55.371578Z","shell.execute_reply":"2022-05-30T22:39:55.370699Z","shell.execute_reply.started":"2022-05-30T22:39:55.366914Z"},"trusted":true},"outputs":[],"source":["def update_coeffs(coeffs, lr):\n","    for layer in coeffs:\n","        layer.sub_(layer.grad * lr)\n","        layer.grad.zero_()"]},{"cell_type":"code","execution_count":119,"metadata":{},"outputs":[],"source":["def update_coeffs(coeffs,lr):\n","    for layer in coeffs:\n","        layer.sub_(layer.grad*lr)\n","        layer.grad.zero_()"]},{"cell_type":"markdown","metadata":{},"source":["That's it -- we're now ready to train our model!"]},{"cell_type":"code","execution_count":120,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:39:58.189982Z","iopub.status.busy":"2022-05-30T22:39:58.189651Z","iopub.status.idle":"2022-05-30T22:39:58.227202Z","shell.execute_reply":"2022-05-30T22:39:58.226226Z","shell.execute_reply.started":"2022-05-30T22:39:58.189951Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0.544; 0.538; 0.532; 0.526; 0.519; 0.512; 0.504; 0.495; 0.486; 0.476; 0.465; 0.455; 0.444; 0.434; 0.426; 0.418; 0.412; 0.407; 0.403; 0.400; 0.397; 0.395; 0.393; 0.391; 0.390; 0.389; 0.388; 0.387; 0.387; 0.386; "]}],"source":["coeffs = train_model(lr=1.4)"]},{"cell_type":"code","execution_count":121,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.544; 0.538; 0.532; 0.526; 0.519; 0.512; 0.504; 0.495; 0.486; 0.476; 0.465; 0.455; 0.444; 0.434; 0.426; 0.418; 0.412; 0.407; 0.403; 0.400; 0.397; 0.395; 0.393; 0.391; 0.390; 0.389; 0.388; 0.387; 0.387; 0.386; "]}],"source":["coeffs = train_model(lr=1.4)"]},{"cell_type":"code","execution_count":122,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:40:16.338016Z","iopub.status.busy":"2022-05-30T22:40:16.337512Z","iopub.status.idle":"2022-05-30T22:40:16.368327Z","shell.execute_reply":"2022-05-30T22:40:16.367439Z","shell.execute_reply.started":"2022-05-30T22:40:16.337959Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0.544; 0.464; 0.388; 0.382; 0.381; 0.380; 0.380; 0.380; 0.379; 0.379; 0.379; 0.379; 0.379; 0.379; 0.379; 0.379; 0.379; 0.379; 0.379; 0.379; 0.379; 0.379; 0.379; 0.379; 0.379; 0.379; 0.379; 0.379; 0.379; 0.379; "]}],"source":["coeffs = train_model(lr=20)"]},{"cell_type":"markdown","metadata":{},"source":["It's looking good -- our loss is lower than before. Let's see if that translates to a better result on the validation set:"]},{"cell_type":"code","execution_count":123,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:40:18.644458Z","iopub.status.busy":"2022-05-30T22:40:18.644153Z","iopub.status.idle":"2022-05-30T22:40:18.651372Z","shell.execute_reply":"2022-05-30T22:40:18.650102Z","shell.execute_reply.started":"2022-05-30T22:40:18.644427Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor(0.5955)"]},"execution_count":123,"metadata":{},"output_type":"execute_result"}],"source":["\n","acc(coeffs)"]},{"cell_type":"markdown","metadata":{},"source":["In this case our neural net isn't showing better results than the linear model. That's not surprising; this dataset is very small and very simple, and isn't the kind of thing we'd expect to see neural networks excel at. Furthermore, our validation set is too small to reliably see much accuracy difference. But the key thing is that we now know exactly what a real neural net looks like!"]},{"cell_type":"markdown","metadata":{},"source":["## Deep learning"]},{"cell_type":"markdown","metadata":{},"source":["The neural net in the previous section only uses one hidden layer, so it doesn't count as \"deep\" learning. But we can use the exact same technique to make our neural net deep, by adding more matrix multiplications.\n","\n","First, we'll need to create additional coefficients for each layer:"]},{"cell_type":"code","execution_count":124,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:40:55.255291Z","iopub.status.busy":"2022-05-30T22:40:55.25457Z","iopub.status.idle":"2022-05-30T22:40:55.261806Z","shell.execute_reply":"2022-05-30T22:40:55.261271Z","shell.execute_reply.started":"2022-05-30T22:40:55.255242Z"},"trusted":true},"outputs":[],"source":["def init_coeffs():\n","    hiddens = [10, 10]  # <-- set this to the size of each hidden layer you want\n","    sizes = [n_coeff] + hiddens + [1]\n","    n = len(sizes)\n","    layers = [(torch.rand(sizes[i], sizes[i+1])-0.3)/sizes[i+1]*4 for i in range(n-1)]\n","    consts = [(torch.rand(1)[0]-0.5)*0.1 for i in range(n-1)]\n","    for l in layers+consts: l.requires_grad_()\n","    '''åˆ—è¡¨ï¼‹åˆ—è¡¨è¿˜æ˜¯åˆ—è¡¨\n","    [1,2,3]+[4,5,6]\n","    ->[1, 2, 3, 4, 5, 6]\n","    '''\n","    return layers,consts"]},{"cell_type":"code","execution_count":125,"metadata":{},"outputs":[],"source":["def init_coeffs():\n","    hiddens = [10,10]\n","    sizes = [n_coeff] + hiddens + [1]\n","    n = len(sizes)\n","    layers = [(torch.rand(sizes[i],sizes[i+1])-0.3)/sizes[i+1]*4 for i in range(n-1)]\n","    consts = [(torch.rand(1)[0]-0.5)*0.1 for i in range(n-1)]\n","    for l in layers+consts: l.requires_grad_()\n","    return layers,consts\n"]},{"cell_type":"markdown","metadata":{},"source":["You'll notice here that there's a lot of messy constants to get the random numbers in just the right ranges. When you train the model in a moment, you'll see that the tiniest changes to these initialisations can cause our model to fail to train at all! This is a key reason that deep learning failed to make much progress in the early days -- it's very finicky to get a good starting point for our coefficients. Nowadays, we have ways to deal with that, which we'll learn about in other notebooks.\n","\n","Our deep learning `calc_preds` looks much the same as before, but now we loop through each layer, instead of listing them separately:"]},{"cell_type":"code","execution_count":126,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:40:57.610974Z","iopub.status.busy":"2022-05-30T22:40:57.610142Z","iopub.status.idle":"2022-05-30T22:40:57.618154Z","shell.execute_reply":"2022-05-30T22:40:57.617329Z","shell.execute_reply.started":"2022-05-30T22:40:57.610916Z"},"trusted":true},"outputs":[],"source":["import torch.nn.functional as F\n","\n","def calc_preds(coeffs, indeps):\n","    layers,consts = coeffs\n","    n = len(layers)\n","    res = indeps\n","    for i,l in enumerate(layers):\n","        '''iæ˜¯ç´¢å¼•ï¼Œlæ˜¯å¯¹åº”çš„å€¼'''\n","        res = res@l + consts[i]\n","        if i!=n-1: res = F.relu(res)\n","    return torch.sigmoid(res)"]},{"cell_type":"code","execution_count":127,"metadata":{},"outputs":[],"source":["import torch.nn.functional as F\n","def calc_preds(coeffs,indeps):\n","    layers,consts = coeffs\n","    n = len(layers)\n","    res = indeps\n","    for i,l in enumerate(layers):\n","        res = res@l + consts[i]\n","        if i!= n-1: res = F.relu(res)\n","    return torch.sigmoid(res)"]},{"cell_type":"markdown","metadata":{},"source":["We also need a minor update to `update_coeffs` since we've got `layers` and `consts` separated now:"]},{"cell_type":"code","execution_count":128,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:41:08.513049Z","iopub.status.busy":"2022-05-30T22:41:08.512494Z","iopub.status.idle":"2022-05-30T22:41:08.519219Z","shell.execute_reply":"2022-05-30T22:41:08.518093Z","shell.execute_reply.started":"2022-05-30T22:41:08.512999Z"},"trusted":true},"outputs":[],"source":["def update_coeffs(coeffs, lr):\n","    layers,consts = coeffs\n","    for layer in layers+consts:\n","        layer.sub_(layer.grad * lr)\n","        layer.grad.zero_()"]},{"cell_type":"code","execution_count":129,"metadata":{},"outputs":[],"source":["def update_coeffs(coeffs,lr):\n","    layers,consts = coeffs\n","    for layer in layers+consts:\n","        layer.sub_(layer.grad * lr)\n","        layer.grad.zero_()"]},{"cell_type":"markdown","metadata":{},"source":["Let's train our model..."]},{"cell_type":"code","execution_count":130,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:41:23.633004Z","iopub.status.busy":"2022-05-30T22:41:23.632516Z","iopub.status.idle":"2022-05-30T22:41:23.666981Z","shell.execute_reply":"2022-05-30T22:41:23.666048Z","shell.execute_reply.started":"2022-05-30T22:41:23.632953Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0.531; 0.484; 0.470; 0.457; 0.447; 0.437; 0.430; 0.424; 0.419; 0.414; 0.411; 0.408; 0.405; 0.403; 0.401; 0.400; 0.398; 0.397; 0.396; 0.395; 0.394; 0.393; 0.392; 0.392; 0.391; 0.391; 0.390; 0.390; 0.389; 0.389; "]}],"source":["coeffs = train_model(lr=4)"]},{"cell_type":"code","execution_count":131,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.531; 0.484; 0.470; 0.457; 0.447; 0.437; 0.430; 0.424; 0.419; 0.414; 0.411; 0.408; 0.405; 0.403; 0.401; 0.400; 0.398; 0.397; 0.396; 0.395; 0.394; 0.393; 0.392; 0.392; 0.391; 0.391; 0.390; 0.390; 0.389; 0.389; "]}],"source":["coeffs = train_model(lr=4)"]},{"cell_type":"markdown","metadata":{},"source":["...and check its accuracy:"]},{"cell_type":"code","execution_count":132,"metadata":{"execution":{"iopub.execute_input":"2022-05-30T22:41:25.491182Z","iopub.status.busy":"2022-05-30T22:41:25.490656Z","iopub.status.idle":"2022-05-30T22:41:25.497888Z","shell.execute_reply":"2022-05-30T22:41:25.49695Z","shell.execute_reply.started":"2022-05-30T22:41:25.491146Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor(0.5955)"]},"execution_count":132,"metadata":{},"output_type":"execute_result"}],"source":["acc(coeffs)"]},{"cell_type":"markdown","metadata":{},"source":["## Final thoughts"]},{"cell_type":"markdown","metadata":{},"source":["It's actually pretty cool that we've managed to create a real deep learning model from scratch and trained it to get over 80% accuracy on this task, all in the course of a single notebook!\n","\n","The \"real\" deep learning models that are used in research and industry look very similar to this, and in fact if you look inside the source code of any deep learning model you'll recognise the basic steps are the same.\n","\n","The biggest differences in practical models to what we have above are:\n","\n","- How initialisation and normalisation is done to ensure the model trains correctly every time\n","- Regularization (to avoid over-fitting)\n","- Modifying the neural net itself to take advantage of knowledge of the problem domain\n","- Doing gradient descent steps on smaller batches, rather than the whole dataset.\n","\n","I'll be adding notebooks about all these later, and will add links here once they're ready.\n","\n","If you found this notebook useful, please remember to click the little up-arrow at the top to upvote it, since I like to know when people have found my work useful, and it helps others find it too. (BTW, be sure you're looking at my [original notebook here](https://www.kaggle.com/code/jhoward/linear-model-and-neural-net-from-scratch) when you do that, and are not on your own copy of it, otherwise your upvote won't get counted!) And if you have any questions or comments, please pop them below -- I read every comment I receive!"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
